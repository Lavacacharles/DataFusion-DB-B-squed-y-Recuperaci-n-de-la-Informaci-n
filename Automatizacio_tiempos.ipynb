{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index dropped (if existed)\n",
      "Table emptied\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from preprocesamiento import preprocesamiento\n",
    "\n",
    "\n",
    "# Put your credentials\n",
    "conn = psycopg2.connect(\n",
    "    database=\"bd2_proyecto\",\n",
    "    host=\"localhost\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    port=\"5432\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create table\n",
    "def create_table():\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            CREATE TABLE IF NOT EXITS songs (\n",
    "                track_id varchar(22),\n",
    "                lyrics varchar(27698),\n",
    "                track_name varchar(123),\n",
    "                track_artist varchar(51),\n",
    "                track_album_name varchar(151),\n",
    "                playlist_name varchar(120),\n",
    "                playlist_genre varchar(5),\n",
    "                playlist_subgenre varchar(25),\n",
    "                language varchar(2),\n",
    "                info_vector tsvector\n",
    "        );\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.close()\n",
    "        conn.commit()\n",
    "        print(\"Table created\")\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "\n",
    "\n",
    "def insert_all(csv_path, columns):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        columns_parsed = \", \".join(columns)\n",
    "\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM songs\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        if count == 0:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df[\"language\"] = df[\"language\"].replace({np.nan: None})\n",
    "            command = f\"\"\"\n",
    "            INSERT INTO songs({columns_parsed})\n",
    "            VALUES(%s{\", %s\" * (len(columns) - 1)});\n",
    "            \"\"\"\n",
    "            for _, row in df.iterrows():\n",
    "                values = tuple(row[col] for col in columns)\n",
    "                cursor.execute(command, values)\n",
    "\n",
    "            # Aquí medimos el tiempo con EXPLAIN ANALYZE\n",
    "            explain_command = f\"EXPLAIN ANALYZE {command}\"\n",
    "            cursor.execute(explain_command, values)\n",
    "            results = cursor.fetchall()\n",
    "            insertion_time = extract_time(results)\n",
    "\n",
    "            conn.commit()\n",
    "            print(f\"Tiempo de inserción de datos: {insertion_time} ms\")\n",
    "            return insertion_time\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: \", error)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def set_index():\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Medir tiempo con clock_timestamp\n",
    "        command = \"\"\"\n",
    "        DO $$ \n",
    "        DECLARE\n",
    "            start_time TIMESTAMP;\n",
    "            end_time TIMESTAMP;\n",
    "            duration DOUBLE PRECISION;\n",
    "        BEGIN\n",
    "            start_time := clock_timestamp();\n",
    "            CREATE INDEX IF NOT EXISTS idx_info_vector ON songs USING GIN(info_vector);\n",
    "            end_time := clock_timestamp();\n",
    "            duration := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;  -- Tiempo en ms\n",
    "            INSERT INTO temp_timing(duration) VALUES (duration);  -- Guardar duración temporalmente\n",
    "        END $$;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Crear una tabla temporal para almacenar el tiempo\n",
    "        cursor.execute(\"\"\"\n",
    "        CREATE TEMP TABLE IF NOT EXISTS temp_timing (\n",
    "            duration DOUBLE PRECISION\n",
    "        );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Ejecutar el bloque DO\n",
    "        cursor.execute(command)\n",
    "\n",
    "        # Recuperar el tiempo almacenado\n",
    "        cursor.execute(\"SELECT duration FROM temp_timing;\")\n",
    "        index_creation_time = cursor.fetchone()[0]\n",
    "\n",
    "        print(f\"Tiempo de creación del índice: {index_creation_time:.2f} ms\")\n",
    "        return index_creation_time  \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_index(language):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        command = f\"\"\"\n",
    "        EXPLAIN ANALYZE\n",
    "        UPDATE songs SET info_vector =\n",
    "            setweight(to_tsvector('{language}', COALESCE(track_name, '')), 'A') ||\n",
    "            setweight(to_tsvector('{language}', COALESCE(track_album_name, '')), 'B') ||\n",
    "            setweight(to_tsvector('{language}', COALESCE(track_artist, '')), 'C') ||\n",
    "            setweight(to_tsvector('{language}', COALESCE(lyrics, '')), 'D');\n",
    "        \"\"\"\n",
    "        cursor.execute(command)\n",
    "        results = cursor.fetchall()\n",
    "        update_time = extract_time(results)\n",
    "        conn.commit()\n",
    "        print(f\"Info vector updated in {update_time} ms\")\n",
    "        return update_time\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "def clean():\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        drop_index_command = \"\"\"\n",
    "        DROP INDEX IF EXISTS idx_info_vector;\n",
    "        \"\"\"\n",
    "        cursor.execute(drop_index_command)\n",
    "        print(\"Index dropped (if existed)\")\n",
    "\n",
    "        delete_table_command = \"\"\"\n",
    "        DELETE FROM songs;\n",
    "        \"\"\"\n",
    "        cursor.execute(delete_table_command)\n",
    "        print(\"Table emptied\")\n",
    "\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "\n",
    "def extract_time(time):\n",
    "    \"\"\"\n",
    "    Given the fechall of a explain analyze, it returns the time\n",
    "    \"\"\"\n",
    "    return float(time[-1][0].split(\":\")[1][1:].split(\" \")[0])\n",
    "\n",
    "\n",
    "def search(query, columns, k=10, time=False):\n",
    "    \"\"\"\n",
    "    if time is true, the executed time of the command is returned\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # The query is procesed to put the or operators\n",
    "        query_procesed = preprocesamiento(query)\n",
    "\n",
    "        # Parse columns list so that they are a string of the selected\n",
    "        columns_parsed = \", \".join(columns) + \", \"\n",
    "\n",
    "        # Parse columns list so that they are a string of the selected\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        command = f\"\"\"\n",
    "        SELECT {columns_parsed}\n",
    "               ctid::text as row_position,\n",
    "               ts_rank_cd(info_vector, {query_procesed}) as score\n",
    "        FROM songs, to_tsquery({query_procesed}) query\n",
    "        WHERE info_vector @@ query\n",
    "        ORDER BY score DESC\n",
    "        LIMIT {k};\n",
    "        \"\"\"\n",
    "        if time is False:\n",
    "            cursor.execute(command)\n",
    "            results = cursor.fetchall()\n",
    "        else:\n",
    "            command = \"EXPLAIN ANALYZE \" + command\n",
    "            cursor.execute(command)\n",
    "            results = cursor.fetchall()\n",
    "            results = extract_time(results)\n",
    "\n",
    "        # returns a list with tuples, where every tuple is a row\n",
    "        return results\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "\n",
    "# Use if first time creating\n",
    "# create_table()\n",
    "# set_index()\n",
    "\n",
    "# The below code is for inserting the data\n",
    "clean()\n",
    "columns = [\n",
    "    \"track_id\",\n",
    "    \"lyrics\",\n",
    "    \"track_name\",\n",
    "    \"track_artist\",\n",
    "    \"track_album_name\",\n",
    "    \"playlist_name\",\n",
    "    \"playlist_genre\",\n",
    "    \"playlist_subgenre\",\n",
    "    \"language\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def obtain_times(queries, columns, k):\n",
    "    times = []\n",
    "    for i in queries:\n",
    "        current_time = search(i, columns, k, True)\n",
    "        print(current_time)\n",
    "        times.append(current_time)\n",
    "    return times\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# csv_path = \"datasets/spotify_1000.csv\"\n",
    "# insert_all(csv_path, columns)\n",
    "# update_index(\"english\")\n",
    "\n",
    "# columns = [\"track_id\", \"track_name\", \"track_artist\", \"track_album_name\"]\n",
    "# # Las queries deben estar asi porque con \"\"\" hay más espacio, arruinando el\n",
    "# # preprocesamiento\n",
    "# queries = [\n",
    "#     \"Don't sweat all the little things Just keep your eye on the bigger things Cause if you look a little closer You're gonna get a bigger picture\",\n",
    "#     \"I'mma make your CXRPSE dance Ugh, hop in that Jag, do the dash I shoot a nigga then laugh Bitch, don't talk to me if you ain't on that\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# k = 20\n",
    "# times = obtain_times(queries, columns, k)\n",
    "# for i in range(len(times)):\n",
    "#     print(\"Querry i: \", queries[i])\n",
    "#     print(\"Elapsed time: \", times[i], \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index dropped (if existed)\n",
      "Table emptied\n",
      "Tiempo de creación del índice: 7.03 ms\n",
      "Tiempo de inserción de datos: 0.045 ms\n",
      "Info vector updated in 1164.491 ms\n",
      "548.222\n",
      "266.311\n",
      "Querry i:  Don't sweat all the little things Just keep your eye on the bigger things Cause if you look a little closer You're gonna get a bigger picture\n",
      "Elapsed time:  548.222 ms\n",
      "Querry i:  I'mma make your CXRPSE dance Ugh, hop in that Jag, do the dash I shoot a nigga then laugh Bitch, don't talk to me if you ain't on that\n",
      "Elapsed time:  266.311 ms\n",
      "Index dropped (if existed)\n",
      "Table emptied\n"
     ]
    }
   ],
   "source": [
    "# csv_path = \"datasets/spotify_1000.csv\"\n",
    "\n",
    "# datasets = [\"spotify_1000.csv\", \"spotify_2000.csv\", \"spotify_4000.csv\"]\n",
    "\n",
    "# clean()\n",
    "# #Tiempo de creacion\n",
    "# set_index_time = set_index()\n",
    "\n",
    "# insert_time = insert_all(csv_path, columns)\n",
    "\n",
    "# update_time = update_index(\"english\")\n",
    "\n",
    "# #Tiempo de querys: \n",
    "# columns = [\"track_id\", \"track_name\", \"track_artist\", \"track_album_name\"]\n",
    "# queries = [\n",
    "#     \"Don't sweat all the little things Just keep your eye on the bigger things Cause if you look a little closer You're gonna get a bigger picture\",\n",
    "#     \"I'mma make your CXRPSE dance Ugh, hop in that Jag, do the dash I shoot a nigga then laugh Bitch, don't talk to me if you ain't on that\",\n",
    "# ]\n",
    "\n",
    "# k = 20\n",
    "# times = obtain_times(queries, columns, k)\n",
    "# for i in range(len(times)):\n",
    "#     print(\"Querry i: \", queries[i])\n",
    "#     print(\"Elapsed time: \", times[i], \"ms\")\n",
    "# clean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index dropped (if existed)\n",
      "Table emptied\n",
      "Creacion time\n",
      "Tiempo de creación del índice: 4.63 ms\n",
      "Tiempo de inserción de datos: 0.208 ms\n",
      "Info vector updated in 13029.339 ms\n",
      "Queris timecito\n",
      "9239.846\n",
      "3718.989\n",
      "{'dataset': 'spotify_df_256k.csv', 'creation_time_s': 13.034175999999999, 'average_query_time_s': 6.479417499999999}\n"
     ]
    }
   ],
   "source": [
    "def measure_times_for_datasets(datasets, columns, queries, k, language=\"english\"):\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        csv_path = f\"datasets/{dataset}\"\n",
    "        \n",
    "        clean()\n",
    "        \n",
    "        print(\"Creacion time\")\n",
    "\n",
    "        set_index_time = set_index()  \n",
    "        insert_time = insert_all(csv_path, columns)\n",
    "        \n",
    "        update_time = update_index(language)\n",
    "        \n",
    "        print(\"Queris timecito\")\n",
    "        query_times = obtain_times(queries, columns, k)\n",
    "        average_query_time = sum(query_times) / len(query_times)\n",
    "        \n",
    "        results.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"creation_time_s\": (set_index_time+insert_time+update_time)/ 1000,\n",
    "            \"average_query_time_s\": average_query_time/ 1000,\n",
    "        })\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "    \n",
    "        df.to_csv(\"tiempos_Postgres_256.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# datasets = [\"spotify_1000.csv\", \"spotify_2000.csv\", \"spotify_4000.csv\", \"spotify_8000.csv\"]\n",
    "# datasets = [\"spotify_16000.csv\", \"spotify_32000.csv\", \"spotify_64000.csv\"]\n",
    "datasets = [\"spotify_df_256k.csv\"]\n",
    "columns = [\"track_id\", \"track_name\", \"track_artist\", \"track_album_name\"]\n",
    "queries = [\n",
    "    \"Don't sweat all the little things Just keep your eye on the bigger things Cause if you look a little closer You're gonna get a bigger picture\",\n",
    "    \"I'mma make your CXRPSE dance Ugh, hop in that Jag, do the dash I shoot a nigga then laugh Bitch, don't talk to me if you ain't on that\",\n",
    "]\n",
    "k = 20\n",
    "\n",
    "results = measure_times_for_datasets(datasets, columns, queries, k)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
