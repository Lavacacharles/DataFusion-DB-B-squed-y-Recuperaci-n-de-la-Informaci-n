{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto jiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ce mar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Ce\n",
      "[nltk_data]     mar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ce mar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Ce mar\\.cache\\kagglehub\\datasets\\imuhammad\\audio-features-and-lyrics-of-spotify-songs\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"imuhammad/audio-features-and-lyrics-of-spotify-songs\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords-en.txt\", encoding=\"latin1\") as file:\n",
    "   stoplist = [line.rstrip().lower() for line in file]\n",
    "stoplist += ['?', '-', '.', ':', ',', '!', ';']\n",
    "\n",
    "def preprocesamiento(texto, stemming=True):\n",
    "  words = []\n",
    "  if not isinstance(texto, str):\n",
    "    return words\n",
    "  texto = texto.lower()\n",
    "  texto = re.sub(r'[^a-zA-Z0-9_À-ÿ]', ' ', texto)\n",
    "  # tokenizar\n",
    "  words = nltk.word_tokenize(texto, language='spanish')\n",
    "  # filtrar stopwords\n",
    "  words = [word for word in words if word not in stoplist]\n",
    "  # reducir palabras (stemming)\n",
    "  if stemming:\n",
    "      words = [stemmer.stem(word) for word in words]\n",
    "  return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ce mar\\.cache\\kagglehub\\datasets\\imuhammad\\audio-features-and-lyrics-of-spotify-songs\\versions\\1\\spotify_songs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_id</td>\n",
       "      <td>track_name</td>\n",
       "      <td>track_artist</td>\n",
       "      <td>lyrics</td>\n",
       "      <td>track_popularity</td>\n",
       "      <td>track_album_id</td>\n",
       "      <td>track_album_name</td>\n",
       "      <td>track_album_release_date</td>\n",
       "      <td>playlist_name</td>\n",
       "      <td>playlist_id</td>\n",
       "      <td>...</td>\n",
       "      <td>loudness</td>\n",
       "      <td>mode</td>\n",
       "      <td>speechiness</td>\n",
       "      <td>acousticness</td>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>liveness</td>\n",
       "      <td>valence</td>\n",
       "      <td>tempo</td>\n",
       "      <td>duration_ms</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017A6SJgTbfQVU2EtsPNo</td>\n",
       "      <td>Pangarap</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>Minsan pa Nang ako'y napalingon Hindi ko alam ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1srJQ0njEQgd8w4XSqI4JQ</td>\n",
       "      <td>Trip</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>Pinoy Classic Rock</td>\n",
       "      <td>37i9dQZF1DWYDQ8wBxd7xt</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.5660000000000001</td>\n",
       "      <td>97.091</td>\n",
       "      <td>235440</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004s3t0ONYlzxII9PLgU6z</td>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>The trees, are singing in the wind The sky blu...</td>\n",
       "      <td>28</td>\n",
       "      <td>3z04Lb9Dsilqw68SHt6jLB</td>\n",
       "      <td>Love &amp; Loss</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>Hard Rock Workout</td>\n",
       "      <td>3YouF0u7waJnolytf9JCXf</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.34700000000000003</td>\n",
       "      <td>0.404</td>\n",
       "      <td>135.225</td>\n",
       "      <td>373512</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00chLpzhgVjxs1zKC9UScL</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>NA Yeah, Spyderman and Freeze in full effect U...</td>\n",
       "      <td>0</td>\n",
       "      <td>6oZ6brjB8x3GoeSYdwJdPc</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>Back in the day - R&amp;B, New Jack Swing, Swingbe...</td>\n",
       "      <td>3a9y4eeCJRmG9p4YKfqYIx</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21600000000000005</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.007229999999999999</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.65</td>\n",
       "      <td>111.904</td>\n",
       "      <td>262467</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00cqd6ZsSkLZqGMlQCR0Zo</td>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>I really can't stay Baby it's cold outside I'v...</td>\n",
       "      <td>41</td>\n",
       "      <td>3ssspRe42CXkhPxdc12xcp</td>\n",
       "      <td>CeeLo's Magic Moment</td>\n",
       "      <td>2012-10-29</td>\n",
       "      <td>Christmas Soul</td>\n",
       "      <td>6FZYc2BvF7tColxO8PBShV</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.6890000000000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>118.593</td>\n",
       "      <td>243067</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1   \\\n",
       "0                track_id                                         track_name   \n",
       "1  0017A6SJgTbfQVU2EtsPNo                                           Pangarap   \n",
       "2  004s3t0ONYlzxII9PLgU6z                                       I Feel Alive   \n",
       "3  00chLpzhgVjxs1zKC9UScL                                             Poison   \n",
       "4  00cqd6ZsSkLZqGMlQCR0Zo  Baby It's Cold Outside (feat. Christina Aguilera)   \n",
       "\n",
       "                2                                                  3   \\\n",
       "0     track_artist                                             lyrics   \n",
       "1  Barbie's Cradle  Minsan pa Nang ako'y napalingon Hindi ko alam ...   \n",
       "2    Steady Rollin  The trees, are singing in the wind The sky blu...   \n",
       "3   Bell Biv DeVoe  NA Yeah, Spyderman and Freeze in full effect U...   \n",
       "4      CeeLo Green  I really can't stay Baby it's cold outside I'v...   \n",
       "\n",
       "                 4                       5                     6   \\\n",
       "0  track_popularity          track_album_id      track_album_name   \n",
       "1                41  1srJQ0njEQgd8w4XSqI4JQ                  Trip   \n",
       "2                28  3z04Lb9Dsilqw68SHt6jLB           Love & Loss   \n",
       "3                 0  6oZ6brjB8x3GoeSYdwJdPc                  Gold   \n",
       "4                41  3ssspRe42CXkhPxdc12xcp  CeeLo's Magic Moment   \n",
       "\n",
       "                         7   \\\n",
       "0  track_album_release_date   \n",
       "1                2001-01-01   \n",
       "2                2017-11-21   \n",
       "3                2005-01-01   \n",
       "4                2012-10-29   \n",
       "\n",
       "                                                  8                       9   \\\n",
       "0                                      playlist_name             playlist_id   \n",
       "1                                 Pinoy Classic Rock  37i9dQZF1DWYDQ8wBxd7xt   \n",
       "2                                  Hard Rock Workout  3YouF0u7waJnolytf9JCXf   \n",
       "3  Back in the day - R&B, New Jack Swing, Swingbe...  3a9y4eeCJRmG9p4YKfqYIx   \n",
       "4                                     Christmas Soul  6FZYc2BvF7tColxO8PBShV   \n",
       "\n",
       "   ...        15    16                   17                  18  \\\n",
       "0  ...  loudness  mode          speechiness        acousticness   \n",
       "1  ...   -10.068     1               0.0236               0.279   \n",
       "2  ...    -4.739     1               0.0442              0.0117   \n",
       "3  ...    -7.504     0  0.21600000000000005             0.00432   \n",
       "4  ...    -5.819     0               0.0341  0.6890000000000001   \n",
       "\n",
       "                     19                   20                  21       22  \\\n",
       "0      instrumentalness             liveness             valence    tempo   \n",
       "1                0.0117               0.0887  0.5660000000000001   97.091   \n",
       "2               0.00994  0.34700000000000003               0.404  135.225   \n",
       "3  0.007229999999999999                0.489                0.65  111.904   \n",
       "4                     0               0.0664               0.405  118.593   \n",
       "\n",
       "            23        24  \n",
       "0  duration_ms  language  \n",
       "1       235440        tl  \n",
       "2       373512        en  \n",
       "3       262467        en  \n",
       "4       243067        en  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_ = os.listdir(path)\n",
    "songs = os.path.join(path, lista_[0])\n",
    "print(songs)\n",
    "dataset = pd.read_csv(songs, header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really can't stay Baby it's cold outside I've got to go away Baby it's cold out there This evening has been Been hoping that you'd drop in So very nice I'll hold your hands, they're just like ice My mother will start to worry Beautiful, what's your hurry? My father will be pacing the floor Listen to that fireplace roar So really I'd better scurry Beautiful, please don't hurry Well maybe just a half a drink more Why don't you put some records on while I pour The neighbors might think Baby, it's bad out there Say, what's in this drink? No cabs to be had out there I wish I knew how Your eyes are like starlight To break the spell I'll take your hat, your hair looks swell I ought to say no, no, no, sir Mind if I move in closer? At least I'm gonna say that I tried What's the sense in hurting my pride? I really can't stay Baby don't hold out Baby it's cold outside I simply must go See that it's cold outside The answer is no I said it's cold out there This welcome has been How lucky that you dropped in So nice and warm Look out the window at that storm My sister will be suspicious Gosh, your lips look delicious My brother will be there at the door Waves upon a tropical shore My maiden aunt's mind is vicious Oh, your lips are delicious Maybe just a cigarette more Never such a blizzard before Hey I've got to go home Baby, you'll freeze out there Say, lend me your coat It's up to your knees out there You've really been grand I'm thrilled when you touch my hand But don't you see How can you do this thing to me? There's bound to be talk tomorrow Think of my life long sorrow At least there will be plenty implied If you caught pneumonia and died I really can't stay Get over that old lie Baby, baby it's cold outside\n"
     ]
    }
   ],
   "source": [
    "fila_5 = dataset.iloc[4, 3]\n",
    "print(fila_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "\n",
    "class InvertIndex:\n",
    "    def __init__(self, index_file):\n",
    "        self.index_file = index_file\n",
    "        self.index = {}\n",
    "        self.idf = {}\n",
    "        self.length = {}\n",
    "\n",
    "    def building(self, collection_text, position_text):\n",
    "        total_docs = len(collection_text)\n",
    "        doc_count = {}\n",
    "\n",
    "        # build the inverted index with the collection\n",
    "        for i, row in collection_text.iterrows():\n",
    "          doc_id = i\n",
    "          doc = row.iloc[position_text]\n",
    "          keywords = preprocesamiento(doc)\n",
    "        # compute the tf\n",
    "          tf_per_doc = {}\n",
    "\n",
    "          for keyword in keywords:\n",
    "            if keyword in tf_per_doc:\n",
    "              tf_per_doc[keyword] += 1\n",
    "            else:\n",
    "              tf_per_doc[keyword] = 1\n",
    "          for term in tf_per_doc:\n",
    "            tf_per_doc[term] = math.log10(1 + tf_per_doc[term])\n",
    "\n",
    "        # compute the idf\n",
    "          for term, tf in tf_per_doc.items():\n",
    "            if term not in self.index:\n",
    "                self.index[term] = []\n",
    "            self.index[term].append((doc_id, tf))\n",
    "\n",
    "            if term in doc_count:\n",
    "                doc_count[term] += 1\n",
    "            else:\n",
    "                doc_count[term] = 1\n",
    "\n",
    "        for term, count in doc_count.items():\n",
    "            self.idf[term] = math.log(total_docs / (count))\n",
    "        # compute the length (norm)\n",
    "        for doc_id in range(total_docs):\n",
    "            norm = 0\n",
    "            for term, postings in self.index.items():\n",
    "                for doc, tf in postings:\n",
    "                    if doc == doc_id:\n",
    "                        norm += (tf * self.idf[term]) ** 2\n",
    "            self.length[doc_id] = math.sqrt(norm) #Get sum(tf*idf^2)\n",
    "        # store in disk\n",
    "        with open(self.index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.idf, self.length), f)\n",
    "\n",
    "    def retrieval(self, query, k):\n",
    "        self.load_index()\n",
    "        N = len(self.length)\n",
    "        scores = [0] * len(self.length)\n",
    "        # preprocesar la query: extraer los terminos unicos\n",
    "        terms = preprocesamiento(query)\n",
    "        # calcular el tf-idf del query\n",
    "        tf_query = {}\n",
    "        for term in terms:\n",
    "            if term in tf_query:\n",
    "                tf_query[term] += 1\n",
    "            else:\n",
    "                tf_query[term] = 1\n",
    "        tfidf_query = {}\n",
    "        for term, tf in tf_query.items():   \n",
    "            if term in self.idf:\n",
    "                tfidf_query[term] = math.log10(1 + tf) * self.idf[term]\n",
    "\n",
    "        norm_query = math.sqrt(sum(w_tq**2 for w_tq in tfidf_query.values()))\n",
    "\n",
    "        # aplicar similitud de coseno y guardarlo en el diccionario score\n",
    "        for term, w_tq in tfidf_query.items():\n",
    "            if term in self.index:\n",
    "                for doc, tf_td in self.index[term]:\n",
    "                    w_td = tf_td * self.idf[term] #Calculo tf_idf para wt,d\n",
    "                    scores[doc] += w_td * w_tq\n",
    "                    \n",
    "        for d in range(N):\n",
    "            if self.length[d] != 0:\n",
    "                scores[d] /= self.length[d]*norm_query  # Normalización del documento y la consulta\n",
    "    \n",
    "        # ordenar el score de forma descendente\n",
    "        result = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        # retornamos los k documentos mas relevantes (de mayor similitud al query)\n",
    "        return result[:k]\n",
    "\n",
    "    def load_index(self):\n",
    "        # load index from disk\n",
    "        with open(self.index_file, 'rb') as f:\n",
    "            self.index, self.idf, self.length = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.head(40)\n",
    "\n",
    "# def mostrarDocumentos(result):\n",
    "#     for doc, score in result:\n",
    "#         print(\"Documento\", doc, \" con similitud: \", score)\n",
    "#     print(\"_____\")\n",
    "\n",
    "# index = InvertIndex(\"indice.dat\")\n",
    "# index.building(dataset, 3) #El texto a procesar esta en la posicion 1\n",
    "\n",
    "# Query1 = \"I really can't stay Baby it's cold outside \"\n",
    "# result = index.retrieval(Query1, 10)\n",
    "# print(\"Resultados para\", Query1)\n",
    "# mostrarDocumentos(result)\n",
    "\n",
    "# news_value = dataset.iloc[4, 3] # Sacamos el primer doc el cual nos deberia de dar 1\n",
    "# Query2 = news_value\n",
    "# result2 = index.retrieval(Query2, 10)\n",
    "# print(\"Resultados para\", Query2)\n",
    "# mostrarDocumentos(result2)\n",
    "\n",
    "# Query3 = dataset.iloc[7, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "# Query3 = dataset.iloc[20, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "# Query3 = dataset.iloc[19, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>minsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>napalingon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15846</th>\n",
       "      <td>99</td>\n",
       "      <td>worri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15847</th>\n",
       "      <td>99</td>\n",
       "      <td>unhappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15848</th>\n",
       "      <td>99</td>\n",
       "      <td>unhappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15849</th>\n",
       "      <td>99</td>\n",
       "      <td>unhappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15850</th>\n",
       "      <td>99</td>\n",
       "      <td>babi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index ProcessedText\n",
       "0          1        minsan\n",
       "1          1          nang\n",
       "2          1           ako\n",
       "3          1    napalingon\n",
       "4          1         hindi\n",
       "...      ...           ...\n",
       "15846     99         worri\n",
       "15847     99       unhappi\n",
       "15848     99       unhappi\n",
       "15849     99       unhappi\n",
       "15850     99          babi\n",
       "\n",
       "[15851 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = dataset.head(l)\n",
    "dataset = dataset.head(len(dataset))\n",
    "#Procesar los documentos en pares\n",
    "position_text=3\n",
    "pairs = []\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    if(i!=0):\n",
    "        words = preprocesamiento(row.iloc[position_text])\n",
    "        for text in words:\n",
    "            pairs.append((i, text))\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs, columns=['Index', 'ProcessedText'])\n",
    "pairs_df.head(len(pairs_df))\n",
    "\n",
    "\n",
    "# print(pairs_df[pairs_df[\"ProcessedText\"] == \"6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de niveles serán 7\n",
      "Cantidad de bloques generados 98\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import heapq\n",
    "\n",
    "class SPIMI:\n",
    "    def __init__(self, index_dir=\"index_blocks\"):\n",
    "        self.index_dir = index_dir  \n",
    "        self.block_counter = 0      \n",
    "        self.doc_count = 0  \n",
    "        self.doc_ids = set()         \n",
    "        self.idf = {}\n",
    "        self.length = {}\n",
    "        self.disk_limit = 4000  \n",
    "        self.totalLevels = 0 \n",
    "        self.currentL = 0\n",
    "        self.cuntermerged = 0 \n",
    "\n",
    "        if not os.path.exists(self.index_dir):\n",
    "            os.makedirs(self.index_dir)\n",
    "\n",
    "    def spimi_invert(self, token_stream):\n",
    "        dictionary = {}\n",
    "        for _, row in token_stream.iterrows():\n",
    "            doc_id = row['Index']\n",
    "            token = row['ProcessedText']\n",
    "            self.doc_ids.add(doc_id)\n",
    "            if token not in dictionary:\n",
    "                dictionary[token] = {}  \n",
    "            \n",
    "            if doc_id not in dictionary[token]:\n",
    "                dictionary[token][doc_id] = 1  \n",
    "            else:\n",
    "                dictionary[token][doc_id] += 1  \n",
    "            dictionary_size = sys.getsizeof(dictionary)\n",
    "            if dictionary_size >= self.disk_limit:\n",
    "                self.write_block_to_disk(dictionary, level=0)\n",
    "                dictionary.clear()\n",
    "                \n",
    "        if dictionary:\n",
    "            self.write_block_to_disk(dictionary, level=0)\n",
    "\n",
    "        self.totalLevels = math.ceil(math.log2(self.block_counter))\n",
    "        print(\"La cantidad de niveles serán\", self.totalLevels)\n",
    "        print(\"Cantidad de bloques generados\", self.block_counter)\n",
    "\n",
    "        ##\n",
    "        self.load_index()\n",
    "        self.calculate_idf()\n",
    "        \n",
    "    def write_block_to_disk(self, dictionary, level):\n",
    "        sorted_terms = dict(sorted(dictionary.items())) \n",
    "        file_path = os.path.join(self.index_dir, f\"block_nivel{level}_bloque{self.block_counter}.pkl\")\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(sorted_terms, f)\n",
    "        \n",
    "        self.block_counter += 1\n",
    "\n",
    "    def merge_blocks(self, block1, block2):\n",
    "        merged = block1.copy()\n",
    "        for term, postings in block2.items():\n",
    "            if term in merged:\n",
    "                for doc_id, freq in postings.items():\n",
    "                    if doc_id in merged[term]:\n",
    "                        merged[term][doc_id] += freq\n",
    "                    else:\n",
    "                        merged[term][doc_id] = freq\n",
    "            else:\n",
    "                merged[term] = postings\n",
    "        return dict(sorted(merged.items()))\n",
    "\n",
    "    def load_block(self, filepath):\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def save_merged_block(self, merged_data, level):\n",
    "        file_path = os.path.join(self.index_dir, f\"block_nivel{level}_bloque{self.cuntermerged}.pkl\")\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(merged_data, f)\n",
    "        self.cuntermerged += 1\n",
    "\n",
    "    def merge(self):\n",
    "        for level in range(self.totalLevels):\n",
    "            distance = 2 ** level\n",
    "            files = sorted(os.listdir(self.index_dir))\n",
    "            next_level_files = []\n",
    "            \n",
    "            for i in range(0, len(files), distance * 2):\n",
    "                file1_path = os.path.join(self.index_dir, files[i])\n",
    "                block1 = self.load_block(file1_path)\n",
    "                \n",
    "                if i + distance < len(files):\n",
    "                    file2_path = os.path.join(self.index_dir, files[i + distance])\n",
    "                    block2 = self.load_block(file2_path)\n",
    "                    merged_block = self.merge_blocks(block1, block2)\n",
    "                    # print(f\"Merging files {files[i]} and {files[i + distance]} into new level {level + 1}\")\n",
    "                else:\n",
    "                    merged_block = block1  \n",
    "                    # print(f\"Carrying over {files[i]} to new level {level + 1}\")\n",
    "                \n",
    "                self.save_merged_block(merged_block, level + 1)\n",
    "                next_level_files.append(f\"block_nivel{level + 1}_bloque{self.cuntermerged - 1}.pkl\")\n",
    "\n",
    "            # Delete old blocks of the current level\n",
    "            for filename in files:\n",
    "                if filename.startswith(f\"block_nivel{level}_\"):\n",
    "                    os.remove(os.path.join(self.index_dir, filename))\n",
    "            \n",
    "            # Prepare for next level\n",
    "            files = next_level_files\n",
    "\n",
    "    def retrieval(self, query, k):\n",
    "        self.load_index()  # Cargar el índice\n",
    "        print(\"El index es:\", self.index)\n",
    "        N = len(self.doc_ids )  # Número total de documentos\n",
    "        scores = [0] * N  # Puntuaciones para cada documento\n",
    "        tf_query = {}  # Almacenaremos el TF de los términos de la consulta\n",
    "        terms = preprocesamiento(query)  # Función de preprocesamiento para tokenizar\n",
    "\n",
    "        # Calcular el TF-IDF del query\n",
    "        for term in terms:\n",
    "            if term in tf_query:\n",
    "                tf_query[term] += 1\n",
    "            else:\n",
    "                tf_query[term] = 1\n",
    "        print(\"tf_query es: \", tf_query)\n",
    "\n",
    "        tfidf_query = {}\n",
    "        for term, tf in tf_query.items():\n",
    "            if term in self.idf:\n",
    "                \n",
    "                tfidf_query[term] = math.log10(1 + tf) * self.idf[term]\n",
    "        print(\"tfidf_query es: \", tfidf_query)\n",
    "        norm_query = math.sqrt(sum(w_tq**2 for w_tq in tfidf_query.values()))  # Normalización del query\n",
    "\n",
    "        # Aplicar similitud de coseno: Calculamos el puntaje para cada documento\n",
    "        for term, w_tq in tfidf_query.items():\n",
    "            if term in self.index:\n",
    "                for doc, tf_td in self.index[term]:\n",
    "                    w_td = tf_td * self.idf[term]\n",
    "                    scores[doc] += w_td * w_tq\n",
    "\n",
    "        # Normalizar las puntuaciones de los documentos\n",
    "        for d in range(N):\n",
    "            if self.length.get(d, 0) != 0:\n",
    "                scores[d] /= (self.length.get(d, 1) * norm_query)  # Normalización documento y consulta\n",
    "\n",
    "        # Ordenar las puntuaciones en orden descendente\n",
    "        result = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        print(\"result es\", result)\n",
    "\n",
    "        # Devolver los k documentos más relevantes (top-k)\n",
    "        return result[:k]\n",
    "    \n",
    "    def calculate_idf(self):\n",
    "        for term, postings in self.index.items():\n",
    "            # Número de documentos que contienen el término\n",
    "            doc_freq = len(postings)\n",
    "            # Calcular IDF y almacenar\n",
    "            self.idf[term] = math.log10(len(self.doc_ids) / (1 + doc_freq))\n",
    "        # Calcular la longitud de cada documento\n",
    "        for term, postings in self.index.items():\n",
    "            for doc_id, tf in postings:\n",
    "                if doc_id not in self.length:\n",
    "                    self.length[doc_id] = 0\n",
    "                # Sumar los TF-IDF al cuadrado para la longitud del documento\n",
    "                self.length[doc_id] += (tf * self.idf[term]) ** 2\n",
    "    \n",
    "        # Tomar la raíz cuadrada para completar la longitud de cada documento\n",
    "        for doc_id in self.length:\n",
    "            self.length[doc_id] = math.sqrt(self.length[doc_id])\n",
    "\n",
    "    def load_index(self):\n",
    "        self.index = {}\n",
    "        files = sorted(os.listdir(self.index_dir))\n",
    "        for file in files:\n",
    "            if file.endswith(\".pkl\"):\n",
    "                block = self.load_block(os.path.join(self.index_dir, file))\n",
    "                for term, postings in block.items():\n",
    "                    if term not in self.index:\n",
    "                        self.index[term] = []\n",
    "                    for doc_id, tf in postings.items():\n",
    "                        self.index[term].append((doc_id, tf))\n",
    " \n",
    "    def load_block(self, filepath):\n",
    "        \"\"\" Cargar un bloque del índice desde un archivo. \"\"\"\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = SPIMI()  \n",
    "s.spimi_invert(pairs_df)\n",
    "s.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El index es: {'6': [(2, 1), (2, 1)], 'aaa': [(3, 1), (3, 1)], 'abr': [(25, 1), (25, 1)], 'acaramelao': [(45, 1), (45, 1)], 'acercarm': [(47, 1), (47, 1)], 'acuerd': [(45, 1), (45, 1)], 'adapta': [(45, 1), (45, 1)], 'addict': [(50, 2), (50, 2)], 'age': [(48, 2), (48, 2)], 'ahh': [(26, 4), (26, 4)], 'ain': [(48, 7), (48, 7)], 'ake': [(1, 1), (1, 1)], 'akin': [(1, 4), (1, 4)], 'ako': [(1, 2), (1, 2)], 'alam': [(1, 2), (1, 2)], 'aliv': [(2, 2), (26, 4), (2, 2), (26, 4)], 'aloca': [(45, 2), (45, 2)], 'ang': [(1, 7), (1, 7)], 'angel': [(2, 3), (2, 3)], 'apretao': [(45, 4), (45, 4)], 'apunta': [(45, 1), (45, 1)], 'aqui': [(25, 1), (25, 1)], 'argh': [(45, 1), (45, 1)], 'armani': [(45, 1), (45, 1)], 'arriba': [(45, 12), (45, 12)], 'atentament': [(45, 1), (45, 1)], 'avenida': [(45, 1), (45, 1)], 'ay': [(1, 5), (1, 5)], 'babe': [(50, 2), (50, 2)], 'babi': [(50, 1), (50, 1)], 'bacalao': [(45, 1), (45, 1)], 'backstag': [(26, 2), (26, 2)], 'bad': [(48, 1), (48, 1)], 'bag': [(48, 1), (48, 1)], 'baila': [(45, 6), (45, 6)], 'bailando': [(45, 2), (45, 2)], 'barb': [(50, 2), (50, 2)], 'bawat': [(1, 1), (1, 1)], 'beat': [(26, 2), (49, 2), (26, 2), (49, 2)], 'beauti': [(3, 1), (3, 1)], 'bell': [(48, 1), (48, 1)], 'bench': [(2, 1), (2, 1)], 'besot': [(25, 1), (25, 1)], 'bet': [(48, 1), (48, 1)], 'bewar': [(3, 1), (3, 1)], 'bien': [(45, 12), (45, 12)], 'bitch': [(48, 1), (48, 1)], 'biv': [(3, 1), (3, 1)], 'black': [(48, 1), (48, 1)], 'blew': [(26, 2), (26, 2)], 'blind': [(3, 1), (3, 1)], 'blood': [(50, 2), (50, 2)], 'blue': [(2, 1), (2, 1)], 'blusa': [(45, 1), (45, 1)], 'boca': [(25, 1), (25, 1)], 'bodi': [(45, 1), (45, 1)], 'boogi': [(25, 1), (25, 1)], 'bought': [(26, 2), (26, 2)], 'bound': [(46, 3), (46, 3)], 'bout': [(27, 1), (27, 1)], 'box': [(26, 26), (26, 26)], 'boy': [(48, 2), (48, 2)], 'break': [(3, 1), (3, 1)], 'breakin': [(3, 1), (3, 1)], 'breath': [(48, 1), (48, 1)], 'bring': [(49, 2), (49, 2)], 'brudda': [(48, 1), (48, 1)], 'buck': [(48, 1), (48, 1)], 'bumulong': [(1, 1), (1, 1)], 'burn': [(46, 6), (50, 2), (46, 6), (50, 2)], 'bus': [(48, 1), (48, 1)], 'bust': [(48, 1), (48, 1)], 'butt': [(3, 1), (3, 1)], 'buzzin': [(48, 1), (48, 1)], 'cab': [(48, 1), (48, 1)], 'cachet': [(45, 1), (45, 1)], 'cada': [(45, 1), (45, 1)], 'calentarm': [(47, 2), (47, 2)], 'call': [(51, 1), (51, 1)], 'capitn': [(45, 1), (45, 1)], 'care': [(2, 1), (49, 6), (2, 1), (49, 6)], 'cash': [(27, 1), (48, 2), (27, 1), (48, 2)], 'catch': [(27, 1), (27, 1)], 'caught': [(48, 1), (48, 1)], 'caution': [(3, 1), (3, 1)], 'cerdito': [(45, 1), (45, 1)], 'chainz': [(27, 1), (27, 1)], 'chang': [(26, 2), (26, 2)], 'checkin': [(3, 1), (3, 1)], 'chest': [(3, 1), (3, 1)], 'chick': [(48, 1), (48, 1)], 'chose': [(27, 1), (27, 1)], 'clockin': [(3, 1), (3, 1)], 'close': [(2, 1), (27, 2), (49, 4), (2, 1), (27, 2), (49, 4)], 'coco': [(25, 1), (25, 1)], 'cold': [(49, 2), (50, 17), (49, 2), (50, 17)], 'comin': [(48, 1), (48, 1)], 'como': [(45, 2), (45, 2)], 'conmigo': [(45, 3), (45, 3)], 'controlando': [(45, 1), (45, 1)], 'convers': [(27, 1), (27, 1)], 'cook': [(27, 1), (27, 1)], 'countri': [(48, 3), (48, 3)], 'coupl': [(46, 1), (46, 1)], 'crash': [(27, 1), (27, 1)], 'creada': [(45, 1), (45, 1)], 'crew': [(3, 1), (3, 1)], 'crowd': [(26, 2), (26, 2)], 'cruza': [(45, 1), (45, 1)], 'cuando': [(45, 7), (45, 7)], 'cuddl': [(48, 1), (48, 1)], 'cunani': [(45, 1), (45, 1)], 'cure': [(3, 1), (3, 1)], 'cut': [(3, 1), (50, 2), (3, 1), (50, 2)], 'cuttin': [(48, 1), (48, 1)], 'dale': [(25, 2), (25, 2)], 'dame': [(25, 1), (25, 1)], 'danc': [(2, 1), (2, 1)], 'darat': [(1, 1), (1, 1)], 'dark': [(27, 1), (51, 1), (27, 1), (51, 1)], 'date': [(48, 3), (48, 3)], 'day': [(26, 4), (50, 1), (26, 4), (50, 1)], 'dead': [(3, 3), (3, 3)], 'death': [(27, 1), (27, 1)], 'debajo': [(45, 1), (45, 1)], 'deceiv': [(46, 1), (46, 1)], 'deci': [(25, 1), (25, 1)], 'del': [(25, 1), (45, 2), (25, 1), (45, 2)], 'dem': [(48, 1), (48, 1)], 'demon': [(3, 1), (3, 1)], 'desir': [(46, 3), (46, 3)], 'devo': [(3, 1), (3, 1)], 'die': [(27, 1), (46, 3), (27, 1), (46, 3)], 'dije': [(47, 1), (47, 1)], 'dinero': [(45, 1), (45, 1)], 'dinmico': [(45, 1), (45, 1)], 'dipper': [(48, 1), (48, 1)], 'distant': [(26, 2), (26, 2)], 'ditch': [(48, 1), (48, 1)], 'dito': [(1, 1), (1, 1)], 'dmu': [(48, 1), (48, 1)], 'door': [(26, 2), (26, 2)], 'dos': [(45, 1), (45, 1)], 'doubt': [(51, 1), (51, 1)], 'downpour': [(26, 2), (26, 2)], 'dreamin': [(3, 1), (3, 1)], 'drive': [(3, 1), (3, 1)], 'drivin': [(3, 1), (3, 1)], 'duck': [(48, 2), (48, 2)], 'duo': [(45, 1), (45, 1)], 'ear': [(26, 2), (26, 2)], 'easi': [(46, 1), (46, 1)], 'edg': [(50, 2), (50, 2)], 'ehh': [(45, 4), (45, 4)], 'el': [(45, 13), (47, 1), (45, 13), (47, 1)], 'ella': [(25, 3), (45, 11), (47, 1), (25, 3), (45, 11), (47, 1)], 'em': [(3, 1), (3, 1)], 'emborracha': [(45, 1), (45, 1)], 'emot': [(49, 2), (49, 2)], 'empezo': [(47, 1), (47, 1)], 'empolvao': [(45, 1), (45, 1)], 'en': [(45, 3), (47, 1), (45, 3), (47, 1)], 'encanta': [(45, 1), (45, 1)], 'encima': [(45, 2), (45, 2)], 'ere': [(25, 1), (25, 1)], 'eso': [(45, 2), (45, 2)], 'espacio': [(47, 1), (47, 1)], 'eye': [(3, 1), (26, 20), (27, 3), (3, 1), (26, 20), (27, 3)], 'faith': [(51, 1), (51, 1)], 'fall': [(3, 1), (46, 1), (51, 1), (3, 1), (46, 1), (51, 1)], 'fam': [(27, 1), (27, 1)], 'fantica': [(45, 1), (45, 1)], 'fast': [(49, 2), (49, 2)], 'fear': [(27, 2), (27, 2)], 'fed': [(48, 2), (48, 2)], 'feel': [(2, 2), (49, 6), (50, 38), (2, 2), (49, 6), (50, 38)], 'feet': [(50, 1), (50, 1)], 'fella': [(3, 1), (3, 1)], 'fellow': [(3, 1), (3, 1)], 'fenc': [(2, 1), (2, 1)], 'fiesta': [(25, 1), (25, 1)], 'fill': [(48, 1), (48, 1)], 'fine': [(45, 1), (45, 1)], 'flame': [(46, 6), (46, 6)], 'fli': [(3, 2), (3, 2)], 'flood': [(48, 3), (48, 3)], 'foreign': [(48, 1), (48, 1)], 'forget': [(49, 6), (49, 6)], 'freez': [(3, 1), (3, 1)], 'friday': [(48, 2), (48, 2)], 'fro': [(3, 1), (3, 1)], 'frontiando': [(45, 1), (45, 1)], 'frontua': [(45, 1), (45, 1)], 'fuck': [(50, 1), (50, 1)], 'funki': [(48, 2), (48, 2)], 'funni': [(46, 1), (46, 1)], 'game': [(48, 1), (48, 1)], 'ganandom': [(47, 1), (47, 1)], 'gand': [(48, 1), (48, 1)], 'gawin': [(1, 1), (1, 1)], 'gettin': [(3, 1), (27, 1), (3, 1), (27, 1)], 'gift': [(48, 1), (48, 1)], 'girl': [(3, 5), (27, 1), (48, 4), (50, 2), (3, 5), (27, 1), (48, 4), (50, 2)], 'gman': [(48, 1), (48, 1)], 'god': [(27, 1), (27, 1)], 'gon': [(26, 6), (27, 1), (46, 6), (49, 24), (26, 6), (27, 1), (46, 6), (49, 24)], 'grito': [(45, 2), (45, 2)], 'ground': [(50, 1), (50, 1)], 'grow': [(50, 1), (50, 1)], 'guaraguao': [(45, 1), (45, 1)], 'guill': [(45, 6), (45, 6)], 'guin': [(45, 1), (45, 1)], 'guitar': [(26, 12), (26, 12)], 'gunshot': [(27, 1), (27, 1)], 'gyal': [(48, 1), (48, 1)], 'hace': [(25, 2), (25, 2)], 'haciendo': [(45, 1), (45, 1)], 'hah': [(25, 2), (25, 2)], 'hand': [(2, 1), (26, 2), (48, 4), (2, 1), (26, 2), (48, 4)], 'hanggang': [(1, 1), (1, 1)], 'hangin': [(1, 1), (1, 1)], 'hard': [(3, 1), (3, 1)], 'harrod': [(48, 1), (48, 1)], 'hate': [(48, 2), (48, 2)], 'head': [(3, 1), (26, 2), (3, 1), (26, 2)], 'heard': [(26, 4), (26, 4)], 'heart': [(3, 2), (46, 1), (49, 2), (50, 3), (3, 2), (46, 1), (49, 2), (50, 3)], 'heavi': [(26, 2), (26, 2)], 'hero': [(26, 26), (26, 26)], 'hey': [(2, 2), (2, 2)], 'high': [(3, 1), (3, 1)], 'hill': [(49, 4), (49, 4)], 'hindi': [(1, 2), (1, 2)], 'historia': [(45, 1), (45, 1)], 'hmpheard': [(48, 1), (48, 1)], 'hmu': [(48, 1), (48, 1)], 'hmv': [(48, 1), (48, 1)], 'ho': [(3, 1), (3, 1)], 'hoe': [(3, 1), (3, 1)], 'hold': [(48, 2), (50, 1), (48, 2), (50, 1)], 'hoo': [(3, 1), (3, 1)], 'hot': [(49, 2), (49, 2)], 'hous': [(3, 1), (3, 1)], 'huh': [(3, 2), (3, 2)], 'hung': [(26, 2), (26, 2)], 'hurt': [(49, 6), (49, 6)], 'ic': [(48, 1), (48, 1)], 'ic3': [(48, 1), (48, 1)], 'ika': [(1, 1), (1, 1)], 'ikaw': [(1, 1), (1, 1)], 'intent': [(49, 2), (49, 2)], 'interesant': [(45, 1), (45, 1)], 'interior': [(45, 1), (45, 1)], 'isang': [(1, 2), (1, 2)], 'ito': [(1, 1), (1, 1)], 'iyong': [(1, 4), (1, 4)], 'jajaja': [(45, 1), (45, 1)], 'jala': [(45, 1), (45, 1)], 'judg': [(27, 1), (27, 1)], 'jugo': [(47, 1), (47, 1)], 'juke': [(26, 26), (26, 26)], 'jump': [(2, 1), (50, 2), (2, 1), (50, 2)], 'ka': [(1, 5), (1, 5)], 'kailan': [(1, 1), (1, 1)], 'kay': [(1, 4), (1, 4)], 'kaya': [(1, 2), (1, 2)], 'keepin': [(3, 1), (3, 1)], 'khalifa': [(27, 1), (27, 1)], 'kiss': [(2, 3), (3, 1), (27, 1), (2, 3), (3, 1), (27, 1)], 'know': [(2, 1), (2, 1)], 'ko': [(1, 3), (1, 3)], 'kong': [(1, 1), (1, 1)], 'kung': [(1, 1), (1, 1)], 'labio': [(47, 1), (47, 1)], 'laid': [(3, 1), (3, 1)], 'lalo': [(45, 1), (45, 1)], 'lamig': [(1, 4), (1, 4)], 'lang': [(1, 3), (1, 3)], 'langit': [(1, 1), (1, 1)], 'las': [(45, 2), (45, 2)], 'latino': [(45, 1), (45, 1)], 'laugh': [(2, 1), (2, 1)], 'lay': [(3, 1), (3, 1)], 'le': [(45, 12), (47, 1), (45, 12), (47, 1)], 'left': [(48, 2), (48, 2)], 'leg': [(48, 1), (48, 1)], 'lejito': [(45, 1), (45, 1)], 'lengua': [(25, 2), (25, 2)], 'levanta': [(45, 1), (45, 1)], 'liar': [(50, 2), (50, 2)], 'libro': [(45, 1), (45, 1)], 'lie': [(46, 1), (46, 1)], 'life': [(26, 2), (27, 1), (50, 3), (26, 2), (27, 1), (50, 3)], 'light': [(51, 1), (51, 1)], 'lilingon': [(1, 1), (1, 1)], 'linda': [(45, 2), (45, 2)], 'lip': [(2, 1), (2, 1)], 'live': [(48, 1), (50, 2), (48, 1), (50, 2)], 'llega': [(45, 1), (45, 1)], 'lo': [(45, 10), (45, 10)], 'loca': [(25, 1), (45, 2), (25, 1), (45, 2)], 'lone': [(2, 1), (2, 1)], 'lookin': [(3, 1), (3, 1)], 'los': [(45, 2), (47, 1), (45, 2), (47, 1)], 'loser': [(3, 1), (3, 1)], 'lot': [(49, 6), (49, 6)], 'love': [(2, 1), (3, 3), (46, 1), (49, 38), (50, 6), (2, 1), (3, 3), (46, 1), (49, 38), (50, 6)], 'low': [(3, 1), (3, 1)], 'lucro': [(45, 1), (45, 1)], 'mad': [(48, 1), (48, 1)], 'mahn': [(45, 3), (45, 3)], 'mahon': [(45, 1), (45, 1)], 'main': [(48, 1), (48, 1)], 'mami': [(25, 2), (25, 2)], 'man2': [(27, 1), (27, 1)], 'mandem': [(48, 2), (48, 2)], 'mangarap': [(1, 1), (1, 1)], 'manta': [(45, 1), (45, 1)], 'maquilla': [(45, 2), (45, 2)], 'maranta': [(45, 1), (45, 1)], 'marat': [(1, 1), (1, 1)], 'masa': [(45, 1), (45, 1)], 'matando': [(45, 1), (45, 1)], 'medio': [(45, 1), (45, 1)], 'meet': [(3, 1), (3, 1)], 'mellow': [(3, 1), (3, 1)], 'meten': [(45, 1), (45, 1)], 'mga': [(1, 5), (1, 5)], 'mi': [(25, 2), (45, 2), (25, 2), (45, 2)], 'midnight': [(2, 1), (2, 1)], 'mind': [(3, 3), (3, 3)], 'minsan': [(1, 1), (1, 1)], 'mire': [(47, 1), (47, 1)], 'miro': [(47, 1), (47, 1)], 'missus': [(48, 1), (48, 1)], 'modela': [(45, 2), (45, 2)], 'money': [(3, 1), (27, 2), (48, 1), (3, 1), (27, 2), (48, 1)], 'mong': [(1, 4), (1, 4)], 'mordio': [(47, 1), (47, 1)], 'motiv': [(27, 1), (27, 1)], 'moto': [(25, 1), (25, 1)], 'move': [(48, 1), (48, 1)], 'movin': [(3, 1), (3, 1)], 'mucho': [(47, 2), (47, 2)], 'muev': [(45, 1), (45, 1)], 'muli': [(1, 1), (1, 1)], 'mulona': [(25, 1), (25, 1)], 'musica': [(45, 1), (45, 1)], 'muy': [(25, 1), (25, 1)], 'nabitawan': [(1, 1), (1, 1)], 'nacer': [(45, 1), (45, 1)], 'nada': [(25, 2), (25, 2)], 'nakapagbigay': [(1, 4), (1, 4)], 'nalgona': [(25, 1), (25, 1)], 'nang': [(1, 1), (1, 1)], 'napalingon': [(1, 1), (1, 1)], 'navidad': [(45, 1), (45, 1)], 'nazi': [(45, 1), (45, 1)], 'necesito': [(47, 2), (47, 2)], 'neck': [(48, 1), (48, 1)], 'nena': [(45, 2), (45, 2)], 'nesti': [(45, 1), (45, 1)], 'ngiti': [(1, 4), (1, 4)], 'nice': [(48, 1), (48, 1)], 'nigga': [(48, 4), (48, 4)], 'night': [(3, 1), (50, 2), (3, 1), (50, 2)], 'noch': [(45, 1), (45, 1)], 'nosotro': [(45, 1), (45, 1)], 'nuevament': [(45, 1), (45, 1)], 'numb': [(50, 2), (50, 2)], 'organizacin': [(45, 1), (45, 1)], 'otro': [(45, 1), (45, 1)], 'oye': [(45, 3), (45, 3)], 'paid': [(3, 1), (27, 1), (3, 1), (27, 1)], 'palo': [(45, 1), (45, 1)], 'pangarap': [(1, 6), (1, 6)], 'pansin': [(1, 2), (1, 2)], 'paqu': [(25, 1), (25, 1)], 'park': [(2, 1), (3, 1), (2, 1), (3, 1)], 'parti': [(45, 1), (45, 1)], 'pasin': [(45, 1), (45, 1)], 'pass': [(26, 2), (27, 1), (26, 2), (27, 1)], 'passion': [(27, 1), (27, 1)], 'paycat': [(27, 1), (27, 1)], 'pegao': [(45, 28), (45, 28)], 'pelo': [(47, 1), (47, 1)], 'peng': [(48, 1), (48, 1)], 'peopl': [(27, 1), (27, 1)], 'perdi': [(47, 1), (47, 1)], 'perfect': [(27, 1), (27, 1)], 'permeat': [(51, 1), (51, 1)], 'pero': [(25, 1), (45, 2), (25, 1), (45, 2)], 'phone': [(48, 1), (48, 1)], 'pick': [(48, 1), (48, 1)], 'pico': [(45, 1), (45, 1)], 'pictur': [(26, 2), (26, 2)], 'pig': [(48, 1), (48, 1)], 'plastic': [(27, 1), (27, 1)], 'plate': [(48, 1), (48, 1)], 'play': [(3, 1), (26, 2), (3, 1), (26, 2)], 'plug': [(48, 1), (48, 1)], 'poison': [(3, 21), (3, 21)], 'por': [(45, 5), (45, 5)], 'portion': [(3, 1), (3, 1)], 'pour': [(50, 2), (50, 2)], 'power': [(3, 1), (3, 1)], 'preocupacion': [(25, 2), (25, 2)], 'pro': [(3, 1), (3, 1)], 'provoca': [(45, 2), (45, 2)], 'pump': [(50, 2), (50, 2)], 'quier': [(25, 2), (25, 2)], 'quita': [(45, 3), (45, 3)], 'rain': [(26, 4), (26, 4)], 'rambo': [(48, 1), (48, 1)], 'rankiao': [(45, 1), (45, 1)], 'rap': [(48, 1), (48, 1)], 'readi': [(3, 4), (3, 4)], 'reaper': [(51, 1), (51, 1)], 'redempt': [(48, 1), (48, 1)], 'relationship': [(3, 1), (3, 1)], 'remov': [(50, 2), (50, 2)], 'rest': [(3, 1), (3, 1)], 'return': [(51, 1), (51, 1)], 'reverend': [(48, 1), (48, 1)], 'roar': [(26, 2), (26, 2)], 'rock': [(26, 8), (26, 8)], 'rockin': [(26, 4), (26, 4)], 'rodeando': [(45, 1), (45, 1)], 'rojo': [(45, 1), (45, 1)], 'ron': [(3, 1), (3, 1)], 'ropa': [(45, 3), (45, 3)], 'rrrrah': [(25, 1), (25, 1)], 'ruin': [(46, 1), (46, 1)], 'run': [(3, 1), (48, 1), (3, 1), (48, 1)], 'sabe': [(45, 1), (45, 1)], 'sale': [(25, 1), (25, 1)], 'salt': [(45, 1), (50, 2), (45, 1), (50, 2)], 'sana': [(1, 1), (1, 1)], 'sandali': [(1, 2), (1, 2)], 'sayin': [(3, 1), (3, 1)], 'sayo': [(1, 1), (1, 1)], 'scene': [(26, 2), (26, 2)], 'schemin': [(3, 2), (3, 2)], 'scream': [(26, 2), (26, 2)], 'screamin': [(3, 1), (3, 1)], 'secondhand': [(26, 2), (26, 2)], 'sens': [(3, 1), (3, 1)], 'shade': [(49, 2), (49, 2)], 'shadow': [(26, 2), (26, 2)], 'shake': [(3, 1), (3, 1)], 'shock': [(48, 1), (48, 1)], 'shop': [(48, 1), (48, 1)], 'shot': [(27, 1), (27, 1)], 'sient': [(45, 1), (45, 1)], 'sientat': [(25, 1), (25, 1)], 'sign': [(2, 1), (2, 1)], 'sin': [(25, 2), (45, 1), (25, 2), (45, 1)], 'sing': [(2, 1), (2, 1)], 'situat': [(3, 1), (3, 1)], 'skate': [(48, 2), (48, 2)], 'skatin': [(48, 1), (48, 1)], 'skin': [(49, 4), (49, 4)], 'skip': [(49, 2), (49, 2)], 'sky': [(2, 1), (2, 1)], 'slick': [(3, 1), (3, 1)], 'slow': [(3, 1), (27, 1), (49, 2), (3, 1), (27, 1), (49, 2)], 'slung': [(26, 2), (26, 2)], 'smile': [(2, 3), (3, 1), (2, 3), (3, 1)], 'snap': [(48, 1), (48, 1)], 'sociedad': [(45, 2), (45, 2)], 'soft': [(2, 2), (2, 2)], 'sold': [(26, 2), (26, 2)], 'spyderman': [(3, 1), (3, 1)], 'stand': [(26, 2), (26, 2)], 'star': [(26, 20), (26, 20)], 'start': [(3, 2), (26, 2), (3, 2), (26, 2)], 'stay': [(50, 1), (50, 1)], 'steal': [(3, 1), (3, 1)], 'stood': [(3, 1), (3, 1)], 'store': [(26, 2), (26, 2)], 'stove': [(27, 1), (27, 1)], 'straight': [(51, 1), (51, 1)], 'strang': [(3, 1), (3, 1)], 'string': [(26, 2), (26, 2)], 'struggl': [(48, 1), (48, 1)], 'stylish': [(48, 1), (48, 1)], 'sun': [(2, 1), (2, 1)], 'supplier': [(50, 2), (50, 2)], 'ta': [(26, 6), (46, 15), (48, 1), (26, 6), (46, 15), (48, 1)], 'takin': [(3, 1), (3, 1)], 'talk': [(48, 1), (48, 1)], 'tani': [(45, 1), (45, 1)], 'tanong': [(1, 1), (1, 1)], 'te': [(25, 3), (45, 2), (25, 3), (45, 2)], 'terreno': [(47, 1), (47, 1)], 'ticket': [(26, 4), (26, 4)], 'tiempo': [(47, 1), (47, 1)], 'tien': [(25, 1), (25, 1)], 'time': [(3, 1), (46, 1), (3, 1), (46, 1)], 'tingin': [(1, 1), (1, 1)], 'tinig': [(1, 4), (1, 4)], 'toca': [(45, 2), (45, 2)], 'toco': [(47, 1), (47, 1)], 'todo': [(25, 2), (25, 2)], 'told': [(48, 1), (48, 1)], 'tonight': [(26, 4), (26, 4)], 'toqu': [(47, 1), (47, 1)], 'totoo': [(1, 1), (1, 1)], 'town': [(26, 2), (26, 2)], 'tra': [(45, 3), (45, 3)], 'trago': [(25, 1), (25, 1)], 'trap': [(48, 2), (48, 2)], 'tree': [(2, 2), (2, 2)], 'tremendo': [(25, 2), (25, 2)], 'trip': [(26, 2), (26, 2)], 'trust': [(3, 1), (3, 1)], 'tu': [(25, 3), (25, 3)], 'tumbao': [(45, 1), (45, 1)], 'tutugon': [(1, 1), (1, 1)], 'uh': [(3, 1), (3, 1)], 'ulit': [(1, 1), (1, 1)], 'una': [(25, 1), (45, 1), (25, 1), (45, 1)], 'understand': [(26, 2), (26, 2)], 'usa': [(45, 1), (45, 1)], 'vacat': [(27, 1), (48, 2), (27, 1), (48, 2)], 'vacilon': [(25, 2), (25, 2)], 'vamo': [(25, 4), (25, 4)], 'vaquero': [(45, 1), (45, 1)], 'vea': [(25, 1), (25, 1)], 'vein': [(50, 2), (50, 2)], 'veo': [(25, 6), (25, 6)], 'victor': [(45, 1), (45, 1)], 'vid': [(48, 1), (48, 1)], 'vida': [(25, 4), (25, 4)], 'vien': [(25, 1), (25, 1)], 'vivir': [(25, 4), (25, 4)], 'volviendo': [(45, 1), (45, 1)], 'vos': [(45, 1), (45, 1)], 'voto': [(25, 1), (25, 1)], 'vuelv': [(45, 2), (45, 2)], 'waist': [(48, 1), (48, 1)], 'walk': [(51, 1), (51, 1)], 'wall': [(3, 1), (26, 2), (3, 1), (26, 2)], 'wan': [(46, 1), (48, 1), (49, 24), (50, 2), (46, 1), (48, 1), (49, 24), (50, 2)], 'warn': [(3, 1), (3, 1)], 'wave': [(49, 2), (49, 2)], 'west': [(48, 1), (48, 1)], 'whisper': [(49, 2), (49, 2)], 'wife': [(48, 1), (48, 1)], 'wind': [(2, 1), (2, 1)], 'winner': [(3, 1), (48, 1), (3, 1), (48, 1)], 'wire': [(50, 2), (50, 2)], 'woah': [(26, 2), (26, 2)], 'worri': [(46, 1), (46, 1)], 'worst': [(49, 2), (49, 2)], 'worth': [(49, 12), (49, 12)], 'wound': [(50, 2), (50, 2)], 'wrong': [(3, 1), (3, 1)], 'ya': [(45, 1), (45, 1)], 'yandel': [(45, 3), (45, 3)], 'yata': [(1, 1), (1, 1)], 'yeah': [(3, 2), (25, 1), (26, 4), (27, 1), (3, 2), (25, 1), (26, 4), (27, 1)], 'yo': [(25, 4), (45, 4), (47, 2), (25, 4), (45, 4), (47, 2)], 'youngen': [(48, 1), (48, 1)]}\n",
      "tf_query es:  {'yeah': 3, 'spyderman': 1, 'freez': 1, 'uh': 1, 'huh': 2, 'readi': 4, 'ron': 1, 'biv': 3, 'slick': 2, 'break': 1, 'girl': 7, 'warn': 1, 'sens': 1, 'strang': 1, 'mind': 4, 'situat': 1, 'cure': 1, 'run': 1, 'time': 1, 'beauti': 1, 'relationship': 1, 'start': 2, 'dead': 4, 'love': 4, 'heart': 2, 'drivin': 2, 'hard': 2, 'head': 2, 'kiss': 2, 'wrong': 2, 'poison': 25, 'trust': 2, 'butt': 2, 'smile': 2, 'caution': 1, 'meet': 1, 'fli': 2, 'portion': 1, 'drive': 1, 'steal': 1, 'blind': 1, 'bewar': 1, 'schemin': 2, 'dreamin': 1, 'fall': 1, 'screamin': 1, 'demon': 1, 'hoo': 1, 'movin': 1, 'slow': 1, 'lookin': 1, 'mellow': 1, 'fellow': 1, 'devo': 2, 'gettin': 1, 'paid': 1, 'laid': 1, 'lay': 1, 'hous': 1, 'money': 1, 'pro': 1, 'ho': 1, 'cut': 1, 'aaa': 1, 'fro': 1, 'sayin': 2, 'winner': 1, 'loser': 1, 'crew': 2, 'park': 1, 'shake': 1, 'breakin': 1, 'takin': 1, 'em': 1, 'night': 1, 'play': 1, 'wall': 1, 'checkin': 1, 'fella': 2, 'high': 1, 'low': 1, 'keepin': 1, 'eye': 1, 'clockin': 1, 'hoe': 1, 'stood': 1, 'rest': 1, 'power': 1, 'chest': 1, 'michael': 1, 'runnin': 1, 'bell': 1, 'yo': 3, 'blow': 1, 'mike': 1, 'wassup': 1, 'ralph': 1, 'johnni': 1, 'forget': 1, 'boy': 1, 'brown': 1}\n",
      "tfidf_query es:  {'yeah': 0.12828382747765407, 'spyderman': 0.41818066035280493, 'freez': 0.38900783955719337, 'uh': 0.20139110837113403, 'huh': 0.5787837827201944, 'readi': 0.6131943089687878, 'ron': 0.41818066035280493, 'biv': 0.7780156791143867, 'slick': 0.6165628381847035, 'break': 0.23694254377389187, 'girl': 0.415193055525028, 'warn': 0.41818066035280493, 'sens': 0.36517190940280825, 'strang': 0.38900783955719337, 'mind': 0.4676156725874416, 'situat': 0.38900783955719337, 'cure': 0.41818066035280493, 'run': 0.2453800303177401, 'time': 0.10769577483134503, 'beauti': 0.2859283414340358, 'relationship': 0.41818066035280493, 'start': 0.3095578898268887, 'dead': 0.5697547863190736, 'love': 0.1341222271072324, 'heart': 0.24529033723998522, 'drivin': 0.6165628381847035, 'hard': 0.37554504670709965, 'head': 0.3511390910149294, 'kiss': 0.3399357611010124, 'wrong': 0.47293502894525025, 'poison': 1.8285078997228892, 'trust': 0.5191728559465529, 'butt': 0.5787837827201944, 'smile': 0.45318569906634193, 'caution': 0.41818066035280493, 'meet': 0.3121631584528115, 'fli': 0.45318569906634193, 'portion': 0.41818066035280493, 'drive': 0.2745528511133517, 'steal': 0.41818066035280493, 'blind': 0.3450189176105873, 'bewar': 0.41818066035280493, 'schemin': 0.6628006651860061, 'dreamin': 0.41818066035280493, 'fall': 0.2077697229782803, 'screamin': 0.41818066035280493, 'demon': 0.41818066035280493, 'hoo': 0.38900783955719337, 'movin': 0.3450189176105873, 'slow': 0.25439985932113074, 'lookin': 0.2859283414340358, 'mellow': 0.41818066035280493, 'fellow': 0.41818066035280493, 'devo': 0.6165628381847035, 'gettin': 0.2745528511133517, 'paid': 0.2745528511133517, 'laid': 0.41818066035280493, 'lay': 0.3121631584528115, 'hous': 0.2983887812677368, 'money': 0.16853534921335825, 'pro': 0.41818066035280493, 'ho': 0.3121631584528115, 'cut': 0.2983887812677368, 'aaa': 0.41818066035280493, 'fro': 0.38900783955719337, 'sayin': 0.49476690025438264, 'winner': 0.3450189176105873, 'loser': 0.41818066035280493, 'crew': 0.6165628381847035, 'park': 0.3121631584528115, 'shake': 0.32756160206334844, 'breakin': 0.41818066035280493, 'takin': 0.3121631584528115, 'em': 0.2077697229782803, 'night': 0.1591931139651805, 'play': 0.1591931139651805, 'wall': 0.2983887812677368, 'checkin': 0.41818066035280493, 'fella': 0.5787837827201944, 'high': 0.41818066035280493, 'low': 0.41818066035280493, 'keepin': 0.41818066035280493, 'eye': 0.17859690218266872, 'clockin': 0.41818066035280493, 'hoe': 0.2983887812677368, 'stood': 0.41818066035280493, 'rest': 0.36517190940280825, 'power': 0.36517190940280825, 'chest': 0.36517190940280825, 'michael': 0.5087997186422615, 'runnin': 0.36517190940280825, 'bell': 0.38900783955719337, 'yo': 0.1866294690688772, 'blow': 0.2983887812677368, 'mike': 0.5087997186422615, 'wassup': 0.5087997186422615, 'ralph': 0.5087997186422615, 'johnni': 0.5087997186422615, 'forget': 0.2983887812677368, 'boy': 0.2453800303177401, 'brown': 0.41818066035280493}\n",
      "result es [(3, 0.8147243417307194), (2, 0.07311975525558521), (48, 0.038647277792693426), (49, 0.036239164171551284), (27, 0.023652932611503443), (50, 0.01782729328580895), (26, 0.016671314192897156), (46, 0.006222962755020851), (51, 0.004366027139437769), (25, 0.003657312418642649), (47, 0.001917717454158367), (45, 0.0011927989900727856), (0, 0), (1, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 0.0), (12, 0.0), (13, 0.0), (14, 0.0), (15, 0.0), (16, 0.0), (17, 0.0), (18, 0.0), (19, 0.0), (20, 0.0), (21, 0.0), (22, 0.0), (23, 0.0), (24, 0.0), (28, 0.0), (29, 0.0), (30, 0.0), (31, 0.0), (32, 0.0), (33, 0.0), (34, 0.0), (35, 0.0), (36, 0.0), (37, 0.0), (38, 0.0), (39, 0.0), (40, 0.0), (41, 0.0), (42, 0), (43, 0.0), (44, 0.0), (52, 0.0), (53, 0.0), (54, 0.0), (55, 0.0), (56, 0.0), (57, 0.0), (58, 0.0), (59, 0.0), (60, 0.0), (61, 0.0), (62, 0.0), (63, 0.0), (64, 0.0), (65, 0.0), (66, 0.0), (67, 0.0), (68, 0.0), (69, 0.0), (70, 0.0), (71, 0.0), (72, 0.0), (73, 0.0), (74, 0.0), (75, 0.0), (76, 0.0), (77, 0.0), (78, 0.0), (79, 0.0), (80, 0.0), (81, 0.0), (82, 0.0), (83, 0.0), (84, 0.0), (85, 0.0), (86, 0.0), (87, 0.0), (88, 0.0), (89, 0.0), (90, 0.0), (91, 0.0), (92, 0.0), (93, 0.0), (94, 0.0), (95, 0.0), (96, 0.0), (97, 0.0)]\n",
      "[(3, 0.8147243417307194), (2, 0.07311975525558521), (48, 0.038647277792693426), (49, 0.036239164171551284), (27, 0.023652932611503443)]\n",
      "Documento 3  con similitud:  0.8147243417307194\n",
      "Documento 2  con similitud:  0.07311975525558521\n",
      "Documento 48  con similitud:  0.038647277792693426\n",
      "Documento 49  con similitud:  0.036239164171551284\n",
      "Documento 27  con similitud:  0.023652932611503443\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "def mostrarDocumentos(result):\n",
    "    print(result)\n",
    "    for doc, score in result:\n",
    "        print(\"Documento\", doc, \" con similitud: \", score)\n",
    "    print(\"_____\")   \n",
    "    \n",
    "query = dataset.iloc[3,3]\n",
    "top_k = 5\n",
    "result = s.retrieval(query, top_k)\n",
    "mostrarDocumentos(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: 6\n",
      "  DocID: 2, TF: 2\n",
      "Term: aaa\n",
      "  DocID: 3, TF: 2\n",
      "Term: abr\n",
      "  DocID: 25, TF: 2\n",
      "Term: acaramelao\n",
      "  DocID: 45, TF: 2\n",
      "Term: acercarm\n",
      "  DocID: 47, TF: 2\n",
      "Term: acuerd\n",
      "  DocID: 45, TF: 2\n",
      "Term: adapta\n",
      "  DocID: 45, TF: 2\n",
      "Term: addict\n",
      "  DocID: 50, TF: 4\n",
      "Term: age\n",
      "  DocID: 48, TF: 4\n",
      "Term: ahh\n",
      "  DocID: 26, TF: 8\n",
      "Term: ain\n",
      "  DocID: 48, TF: 14\n",
      "Term: ake\n",
      "  DocID: 1, TF: 2\n",
      "Term: akin\n",
      "  DocID: 1, TF: 8\n",
      "Term: ako\n",
      "  DocID: 1, TF: 4\n",
      "Term: alam\n",
      "  DocID: 1, TF: 4\n",
      "Term: aliv\n",
      "  DocID: 2, TF: 4\n",
      "  DocID: 26, TF: 8\n",
      "Term: aloca\n",
      "  DocID: 45, TF: 4\n",
      "Term: ang\n",
      "  DocID: 1, TF: 14\n",
      "Term: angel\n",
      "  DocID: 2, TF: 6\n",
      "Term: apretao\n",
      "  DocID: 45, TF: 8\n",
      "Term: apunta\n",
      "  DocID: 45, TF: 2\n",
      "Term: aqui\n",
      "  DocID: 25, TF: 2\n",
      "Term: argh\n",
      "  DocID: 45, TF: 2\n",
      "Term: armani\n",
      "  DocID: 45, TF: 2\n",
      "Term: arriba\n",
      "  DocID: 45, TF: 24\n",
      "Term: atentament\n",
      "  DocID: 45, TF: 2\n",
      "Term: avenida\n",
      "  DocID: 45, TF: 2\n",
      "Term: ay\n",
      "  DocID: 1, TF: 10\n",
      "Term: babe\n",
      "  DocID: 50, TF: 4\n",
      "Term: babi\n",
      "  DocID: 50, TF: 2\n",
      "Term: bacalao\n",
      "  DocID: 45, TF: 2\n",
      "Term: backstag\n",
      "  DocID: 26, TF: 4\n",
      "Term: bad\n",
      "  DocID: 48, TF: 2\n",
      "Term: bag\n",
      "  DocID: 48, TF: 2\n",
      "Term: baila\n",
      "  DocID: 45, TF: 12\n",
      "Term: bailando\n",
      "  DocID: 45, TF: 4\n",
      "Term: barb\n",
      "  DocID: 50, TF: 4\n",
      "Term: bawat\n",
      "  DocID: 1, TF: 2\n",
      "Term: beat\n",
      "  DocID: 26, TF: 4\n",
      "  DocID: 49, TF: 4\n",
      "Term: beauti\n",
      "  DocID: 3, TF: 2\n",
      "Term: bell\n",
      "  DocID: 48, TF: 2\n",
      "Term: bench\n",
      "  DocID: 2, TF: 2\n",
      "Term: besot\n",
      "  DocID: 25, TF: 2\n",
      "Term: bet\n",
      "  DocID: 48, TF: 2\n",
      "Term: bewar\n",
      "  DocID: 3, TF: 2\n",
      "Term: bien\n",
      "  DocID: 45, TF: 24\n",
      "Term: bitch\n",
      "  DocID: 48, TF: 2\n",
      "Term: biv\n",
      "  DocID: 3, TF: 2\n",
      "Term: black\n",
      "  DocID: 48, TF: 2\n",
      "Term: blew\n",
      "  DocID: 26, TF: 4\n",
      "Term: blind\n",
      "  DocID: 3, TF: 2\n",
      "Term: blood\n",
      "  DocID: 50, TF: 4\n",
      "Term: blue\n",
      "  DocID: 2, TF: 2\n",
      "Term: blusa\n",
      "  DocID: 45, TF: 2\n",
      "Term: boca\n",
      "  DocID: 25, TF: 2\n",
      "Term: bodi\n",
      "  DocID: 45, TF: 2\n",
      "Term: boogi\n",
      "  DocID: 25, TF: 2\n",
      "Term: bought\n",
      "  DocID: 26, TF: 4\n",
      "Term: bound\n",
      "  DocID: 46, TF: 6\n",
      "Term: bout\n",
      "  DocID: 27, TF: 2\n",
      "Term: box\n",
      "  DocID: 26, TF: 52\n",
      "Term: boy\n",
      "  DocID: 48, TF: 4\n",
      "Term: break\n",
      "  DocID: 3, TF: 2\n",
      "Term: breakin\n",
      "  DocID: 3, TF: 2\n",
      "Term: breath\n",
      "  DocID: 48, TF: 2\n",
      "Term: bring\n",
      "  DocID: 49, TF: 4\n",
      "Term: brudda\n",
      "  DocID: 48, TF: 2\n",
      "Term: buck\n",
      "  DocID: 48, TF: 2\n",
      "Term: bumulong\n",
      "  DocID: 1, TF: 2\n",
      "Term: burn\n",
      "  DocID: 46, TF: 12\n",
      "  DocID: 50, TF: 4\n",
      "Term: bus\n",
      "  DocID: 48, TF: 2\n",
      "Term: bust\n",
      "  DocID: 48, TF: 2\n",
      "Term: butt\n",
      "  DocID: 3, TF: 2\n",
      "Term: buzzin\n",
      "  DocID: 48, TF: 2\n",
      "Term: cab\n",
      "  DocID: 48, TF: 2\n",
      "Term: cachet\n",
      "  DocID: 45, TF: 2\n",
      "Term: cada\n",
      "  DocID: 45, TF: 2\n",
      "Term: calentarm\n",
      "  DocID: 47, TF: 4\n",
      "Term: call\n",
      "  DocID: 51, TF: 2\n",
      "Term: capitn\n",
      "  DocID: 45, TF: 2\n",
      "Term: care\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 49, TF: 12\n",
      "Term: cash\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 48, TF: 4\n",
      "Term: catch\n",
      "  DocID: 27, TF: 2\n",
      "Term: caught\n",
      "  DocID: 48, TF: 2\n",
      "Term: caution\n",
      "  DocID: 3, TF: 2\n",
      "Term: cerdito\n",
      "  DocID: 45, TF: 2\n",
      "Term: chainz\n",
      "  DocID: 27, TF: 2\n",
      "Term: chang\n",
      "  DocID: 26, TF: 4\n",
      "Term: checkin\n",
      "  DocID: 3, TF: 2\n",
      "Term: chest\n",
      "  DocID: 3, TF: 2\n",
      "Term: chick\n",
      "  DocID: 48, TF: 2\n",
      "Term: chose\n",
      "  DocID: 27, TF: 2\n",
      "Term: clockin\n",
      "  DocID: 3, TF: 2\n",
      "Term: close\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 27, TF: 4\n",
      "  DocID: 49, TF: 8\n",
      "Term: coco\n",
      "  DocID: 25, TF: 2\n",
      "Term: cold\n",
      "  DocID: 49, TF: 4\n",
      "  DocID: 50, TF: 34\n",
      "Term: comin\n",
      "  DocID: 48, TF: 2\n",
      "Term: como\n",
      "  DocID: 45, TF: 4\n",
      "Term: conmigo\n",
      "  DocID: 45, TF: 6\n",
      "Term: controlando\n",
      "  DocID: 45, TF: 2\n",
      "Term: convers\n",
      "  DocID: 27, TF: 2\n",
      "Term: cook\n",
      "  DocID: 27, TF: 2\n",
      "Term: countri\n",
      "  DocID: 48, TF: 6\n",
      "Term: coupl\n",
      "  DocID: 46, TF: 2\n",
      "Term: crash\n",
      "  DocID: 27, TF: 2\n",
      "Term: creada\n",
      "  DocID: 45, TF: 2\n",
      "Term: crew\n",
      "  DocID: 3, TF: 2\n",
      "Term: crowd\n",
      "  DocID: 26, TF: 4\n",
      "Term: cruza\n",
      "  DocID: 45, TF: 2\n",
      "Term: cuando\n",
      "  DocID: 45, TF: 14\n",
      "Term: cuddl\n",
      "  DocID: 48, TF: 2\n",
      "Term: cunani\n",
      "  DocID: 45, TF: 2\n",
      "Term: cure\n",
      "  DocID: 3, TF: 2\n",
      "Term: cut\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 50, TF: 4\n",
      "Term: cuttin\n",
      "  DocID: 48, TF: 2\n",
      "Term: dale\n",
      "  DocID: 25, TF: 4\n",
      "Term: dame\n",
      "  DocID: 25, TF: 2\n",
      "Term: danc\n",
      "  DocID: 2, TF: 2\n",
      "Term: darat\n",
      "  DocID: 1, TF: 2\n",
      "Term: dark\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 51, TF: 2\n",
      "Term: date\n",
      "  DocID: 48, TF: 6\n",
      "Term: day\n",
      "  DocID: 26, TF: 8\n",
      "  DocID: 50, TF: 2\n",
      "Term: dead\n",
      "  DocID: 3, TF: 6\n",
      "Term: death\n",
      "  DocID: 27, TF: 2\n",
      "Term: debajo\n",
      "  DocID: 45, TF: 2\n",
      "Term: deceiv\n",
      "  DocID: 46, TF: 2\n",
      "Term: deci\n",
      "  DocID: 25, TF: 2\n",
      "Term: del\n",
      "  DocID: 25, TF: 2\n",
      "  DocID: 45, TF: 4\n",
      "Term: dem\n",
      "  DocID: 48, TF: 2\n",
      "Term: demon\n",
      "  DocID: 3, TF: 2\n",
      "Term: desir\n",
      "  DocID: 46, TF: 6\n",
      "Term: devo\n",
      "  DocID: 3, TF: 2\n",
      "Term: die\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 46, TF: 6\n",
      "Term: dije\n",
      "  DocID: 47, TF: 2\n",
      "Term: dinero\n",
      "  DocID: 45, TF: 2\n",
      "Term: dinmico\n",
      "  DocID: 45, TF: 2\n",
      "Term: dipper\n",
      "  DocID: 48, TF: 2\n",
      "Term: distant\n",
      "  DocID: 26, TF: 4\n",
      "Term: ditch\n",
      "  DocID: 48, TF: 2\n",
      "Term: dito\n",
      "  DocID: 1, TF: 2\n",
      "Term: dmu\n",
      "  DocID: 48, TF: 2\n",
      "Term: door\n",
      "  DocID: 26, TF: 4\n",
      "Term: dos\n",
      "  DocID: 45, TF: 2\n",
      "Term: doubt\n",
      "  DocID: 51, TF: 2\n",
      "Term: downpour\n",
      "  DocID: 26, TF: 4\n",
      "Term: dreamin\n",
      "  DocID: 3, TF: 2\n",
      "Term: drive\n",
      "  DocID: 3, TF: 2\n",
      "Term: drivin\n",
      "  DocID: 3, TF: 2\n",
      "Term: duck\n",
      "  DocID: 48, TF: 4\n",
      "Term: duo\n",
      "  DocID: 45, TF: 2\n",
      "Term: ear\n",
      "  DocID: 26, TF: 4\n",
      "Term: easi\n",
      "  DocID: 46, TF: 2\n",
      "Term: edg\n",
      "  DocID: 50, TF: 4\n",
      "Term: ehh\n",
      "  DocID: 45, TF: 8\n",
      "Term: el\n",
      "  DocID: 45, TF: 26\n",
      "  DocID: 47, TF: 2\n",
      "Term: ella\n",
      "  DocID: 25, TF: 6\n",
      "  DocID: 45, TF: 22\n",
      "  DocID: 47, TF: 2\n",
      "Term: em\n",
      "  DocID: 3, TF: 2\n",
      "Term: emborracha\n",
      "  DocID: 45, TF: 2\n",
      "Term: emot\n",
      "  DocID: 49, TF: 4\n",
      "Term: empezo\n",
      "  DocID: 47, TF: 2\n",
      "Term: empolvao\n",
      "  DocID: 45, TF: 2\n",
      "Term: en\n",
      "  DocID: 45, TF: 6\n",
      "  DocID: 47, TF: 2\n",
      "Term: encanta\n",
      "  DocID: 45, TF: 2\n",
      "Term: encima\n",
      "  DocID: 45, TF: 4\n",
      "Term: ere\n",
      "  DocID: 25, TF: 2\n",
      "Term: eso\n",
      "  DocID: 45, TF: 4\n",
      "Term: espacio\n",
      "  DocID: 47, TF: 2\n",
      "Term: eye\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 26, TF: 40\n",
      "  DocID: 27, TF: 6\n",
      "Term: faith\n",
      "  DocID: 51, TF: 2\n",
      "Term: fall\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 46, TF: 2\n",
      "  DocID: 51, TF: 2\n",
      "Term: fam\n",
      "  DocID: 27, TF: 2\n",
      "Term: fantica\n",
      "  DocID: 45, TF: 2\n",
      "Term: fast\n",
      "  DocID: 49, TF: 4\n",
      "Term: fear\n",
      "  DocID: 27, TF: 4\n",
      "Term: fed\n",
      "  DocID: 48, TF: 4\n",
      "Term: feel\n",
      "  DocID: 2, TF: 4\n",
      "  DocID: 49, TF: 12\n",
      "  DocID: 50, TF: 76\n",
      "Term: feet\n",
      "  DocID: 50, TF: 2\n",
      "Term: fella\n",
      "  DocID: 3, TF: 2\n",
      "Term: fellow\n",
      "  DocID: 3, TF: 2\n",
      "Term: fenc\n",
      "  DocID: 2, TF: 2\n",
      "Term: fiesta\n",
      "  DocID: 25, TF: 2\n",
      "Term: fill\n",
      "  DocID: 48, TF: 2\n",
      "Term: fine\n",
      "  DocID: 45, TF: 2\n",
      "Term: flame\n",
      "  DocID: 46, TF: 12\n",
      "Term: fli\n",
      "  DocID: 3, TF: 4\n",
      "Term: flood\n",
      "  DocID: 48, TF: 6\n",
      "Term: foreign\n",
      "  DocID: 48, TF: 2\n",
      "Term: forget\n",
      "  DocID: 49, TF: 12\n",
      "Term: freez\n",
      "  DocID: 3, TF: 2\n",
      "Term: friday\n",
      "  DocID: 48, TF: 4\n",
      "Term: fro\n",
      "  DocID: 3, TF: 2\n",
      "Term: frontiando\n",
      "  DocID: 45, TF: 2\n",
      "Term: frontua\n",
      "  DocID: 45, TF: 2\n",
      "Term: fuck\n",
      "  DocID: 50, TF: 2\n",
      "Term: funki\n",
      "  DocID: 48, TF: 4\n",
      "Term: funni\n",
      "  DocID: 46, TF: 2\n",
      "Term: game\n",
      "  DocID: 48, TF: 2\n",
      "Term: ganandom\n",
      "  DocID: 47, TF: 2\n",
      "Term: gand\n",
      "  DocID: 48, TF: 2\n",
      "Term: gawin\n",
      "  DocID: 1, TF: 2\n",
      "Term: gettin\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 27, TF: 2\n",
      "Term: gift\n",
      "  DocID: 48, TF: 2\n",
      "Term: girl\n",
      "  DocID: 3, TF: 10\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 48, TF: 8\n",
      "  DocID: 50, TF: 4\n",
      "Term: gman\n",
      "  DocID: 48, TF: 2\n",
      "Term: god\n",
      "  DocID: 27, TF: 2\n",
      "Term: gon\n",
      "  DocID: 26, TF: 12\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 46, TF: 12\n",
      "  DocID: 49, TF: 48\n",
      "Term: grito\n",
      "  DocID: 45, TF: 4\n",
      "Term: ground\n",
      "  DocID: 50, TF: 2\n",
      "Term: grow\n",
      "  DocID: 50, TF: 2\n",
      "Term: guaraguao\n",
      "  DocID: 45, TF: 2\n",
      "Term: guill\n",
      "  DocID: 45, TF: 12\n",
      "Term: guin\n",
      "  DocID: 45, TF: 2\n",
      "Term: guitar\n",
      "  DocID: 26, TF: 24\n",
      "Term: gunshot\n",
      "  DocID: 27, TF: 2\n",
      "Term: gyal\n",
      "  DocID: 48, TF: 2\n",
      "Term: hace\n",
      "  DocID: 25, TF: 4\n",
      "Term: haciendo\n",
      "  DocID: 45, TF: 2\n",
      "Term: hah\n",
      "  DocID: 25, TF: 4\n",
      "Term: hand\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 26, TF: 4\n",
      "  DocID: 48, TF: 8\n",
      "Term: hanggang\n",
      "  DocID: 1, TF: 2\n",
      "Term: hangin\n",
      "  DocID: 1, TF: 2\n",
      "Term: hard\n",
      "  DocID: 3, TF: 2\n",
      "Term: harrod\n",
      "  DocID: 48, TF: 2\n",
      "Term: hate\n",
      "  DocID: 48, TF: 4\n",
      "Term: head\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 26, TF: 4\n",
      "Term: heard\n",
      "  DocID: 26, TF: 8\n",
      "Term: heart\n",
      "  DocID: 3, TF: 4\n",
      "  DocID: 46, TF: 2\n",
      "  DocID: 49, TF: 4\n",
      "  DocID: 50, TF: 6\n",
      "Term: heavi\n",
      "  DocID: 26, TF: 4\n",
      "Term: hero\n",
      "  DocID: 26, TF: 52\n",
      "Term: hey\n",
      "  DocID: 2, TF: 4\n",
      "Term: high\n",
      "  DocID: 3, TF: 2\n",
      "Term: hill\n",
      "  DocID: 49, TF: 8\n",
      "Term: hindi\n",
      "  DocID: 1, TF: 4\n",
      "Term: historia\n",
      "  DocID: 45, TF: 2\n",
      "Term: hmpheard\n",
      "  DocID: 48, TF: 2\n",
      "Term: hmu\n",
      "  DocID: 48, TF: 2\n",
      "Term: hmv\n",
      "  DocID: 48, TF: 2\n",
      "Term: ho\n",
      "  DocID: 3, TF: 2\n",
      "Term: hoe\n",
      "  DocID: 3, TF: 2\n",
      "Term: hold\n",
      "  DocID: 48, TF: 4\n",
      "  DocID: 50, TF: 2\n",
      "Term: hoo\n",
      "  DocID: 3, TF: 2\n",
      "Term: hot\n",
      "  DocID: 49, TF: 4\n",
      "Term: hous\n",
      "  DocID: 3, TF: 2\n",
      "Term: huh\n",
      "  DocID: 3, TF: 4\n",
      "Term: hung\n",
      "  DocID: 26, TF: 4\n",
      "Term: hurt\n",
      "  DocID: 49, TF: 12\n",
      "Term: ic\n",
      "  DocID: 48, TF: 2\n",
      "Term: ic3\n",
      "  DocID: 48, TF: 2\n",
      "Term: ika\n",
      "  DocID: 1, TF: 2\n",
      "Term: ikaw\n",
      "  DocID: 1, TF: 2\n",
      "Term: intent\n",
      "  DocID: 49, TF: 4\n",
      "Term: interesant\n",
      "  DocID: 45, TF: 2\n",
      "Term: interior\n",
      "  DocID: 45, TF: 2\n",
      "Term: isang\n",
      "  DocID: 1, TF: 4\n",
      "Term: ito\n",
      "  DocID: 1, TF: 2\n",
      "Term: iyong\n",
      "  DocID: 1, TF: 8\n",
      "Term: jajaja\n",
      "  DocID: 45, TF: 2\n",
      "Term: jala\n",
      "  DocID: 45, TF: 2\n",
      "Term: judg\n",
      "  DocID: 27, TF: 2\n",
      "Term: jugo\n",
      "  DocID: 47, TF: 2\n",
      "Term: juke\n",
      "  DocID: 26, TF: 52\n",
      "Term: jump\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 50, TF: 4\n",
      "Term: ka\n",
      "  DocID: 1, TF: 10\n",
      "Term: kailan\n",
      "  DocID: 1, TF: 2\n",
      "Term: kay\n",
      "  DocID: 1, TF: 8\n",
      "Term: kaya\n",
      "  DocID: 1, TF: 4\n",
      "Term: keepin\n",
      "  DocID: 3, TF: 2\n",
      "Term: khalifa\n",
      "  DocID: 27, TF: 2\n",
      "Term: kiss\n",
      "  DocID: 2, TF: 6\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 27, TF: 2\n",
      "Term: know\n",
      "  DocID: 2, TF: 2\n",
      "Term: ko\n",
      "  DocID: 1, TF: 6\n",
      "Term: kong\n",
      "  DocID: 1, TF: 2\n",
      "Term: kung\n",
      "  DocID: 1, TF: 2\n",
      "Term: labio\n",
      "  DocID: 47, TF: 2\n",
      "Term: laid\n",
      "  DocID: 3, TF: 2\n",
      "Term: lalo\n",
      "  DocID: 45, TF: 2\n",
      "Term: lamig\n",
      "  DocID: 1, TF: 8\n",
      "Term: lang\n",
      "  DocID: 1, TF: 6\n",
      "Term: langit\n",
      "  DocID: 1, TF: 2\n",
      "Term: las\n",
      "  DocID: 45, TF: 4\n",
      "Term: latino\n",
      "  DocID: 45, TF: 2\n",
      "Term: laugh\n",
      "  DocID: 2, TF: 2\n",
      "Term: lay\n",
      "  DocID: 3, TF: 2\n",
      "Term: le\n",
      "  DocID: 45, TF: 24\n",
      "  DocID: 47, TF: 2\n",
      "Term: left\n",
      "  DocID: 48, TF: 4\n",
      "Term: leg\n",
      "  DocID: 48, TF: 2\n",
      "Term: lejito\n",
      "  DocID: 45, TF: 2\n",
      "Term: lengua\n",
      "  DocID: 25, TF: 4\n",
      "Term: levanta\n",
      "  DocID: 45, TF: 2\n",
      "Term: liar\n",
      "  DocID: 50, TF: 4\n",
      "Term: libro\n",
      "  DocID: 45, TF: 2\n",
      "Term: lie\n",
      "  DocID: 46, TF: 2\n",
      "Term: life\n",
      "  DocID: 26, TF: 4\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 50, TF: 6\n",
      "Term: light\n",
      "  DocID: 51, TF: 2\n",
      "Term: lilingon\n",
      "  DocID: 1, TF: 2\n",
      "Term: linda\n",
      "  DocID: 45, TF: 4\n",
      "Term: lip\n",
      "  DocID: 2, TF: 2\n",
      "Term: live\n",
      "  DocID: 48, TF: 2\n",
      "  DocID: 50, TF: 4\n",
      "Term: llega\n",
      "  DocID: 45, TF: 2\n",
      "Term: lo\n",
      "  DocID: 45, TF: 20\n",
      "Term: loca\n",
      "  DocID: 25, TF: 2\n",
      "  DocID: 45, TF: 4\n",
      "Term: lone\n",
      "  DocID: 2, TF: 2\n",
      "Term: lookin\n",
      "  DocID: 3, TF: 2\n",
      "Term: los\n",
      "  DocID: 45, TF: 4\n",
      "  DocID: 47, TF: 2\n",
      "Term: loser\n",
      "  DocID: 3, TF: 2\n",
      "Term: lot\n",
      "  DocID: 49, TF: 12\n",
      "Term: love\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 3, TF: 6\n",
      "  DocID: 46, TF: 2\n",
      "  DocID: 49, TF: 76\n",
      "  DocID: 50, TF: 12\n",
      "Term: low\n",
      "  DocID: 3, TF: 2\n",
      "Term: lucro\n",
      "  DocID: 45, TF: 2\n",
      "Term: mad\n",
      "  DocID: 48, TF: 2\n",
      "Term: mahn\n",
      "  DocID: 45, TF: 6\n",
      "Term: mahon\n",
      "  DocID: 45, TF: 2\n",
      "Term: main\n",
      "  DocID: 48, TF: 2\n",
      "Term: mami\n",
      "  DocID: 25, TF: 4\n",
      "Term: man2\n",
      "  DocID: 27, TF: 2\n",
      "Term: mandem\n",
      "  DocID: 48, TF: 4\n",
      "Term: mangarap\n",
      "  DocID: 1, TF: 2\n",
      "Term: manta\n",
      "  DocID: 45, TF: 2\n",
      "Term: maquilla\n",
      "  DocID: 45, TF: 4\n",
      "Term: maranta\n",
      "  DocID: 45, TF: 2\n",
      "Term: marat\n",
      "  DocID: 1, TF: 2\n",
      "Term: masa\n",
      "  DocID: 45, TF: 2\n",
      "Term: matando\n",
      "  DocID: 45, TF: 2\n",
      "Term: medio\n",
      "  DocID: 45, TF: 2\n",
      "Term: meet\n",
      "  DocID: 3, TF: 2\n",
      "Term: mellow\n",
      "  DocID: 3, TF: 2\n",
      "Term: meten\n",
      "  DocID: 45, TF: 2\n",
      "Term: mga\n",
      "  DocID: 1, TF: 10\n",
      "Term: mi\n",
      "  DocID: 25, TF: 4\n",
      "  DocID: 45, TF: 4\n",
      "Term: midnight\n",
      "  DocID: 2, TF: 2\n",
      "Term: mind\n",
      "  DocID: 3, TF: 6\n",
      "Term: minsan\n",
      "  DocID: 1, TF: 2\n",
      "Term: mire\n",
      "  DocID: 47, TF: 2\n",
      "Term: miro\n",
      "  DocID: 47, TF: 2\n",
      "Term: missus\n",
      "  DocID: 48, TF: 2\n",
      "Term: modela\n",
      "  DocID: 45, TF: 4\n",
      "Term: money\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 27, TF: 4\n",
      "  DocID: 48, TF: 2\n",
      "Term: mong\n",
      "  DocID: 1, TF: 8\n",
      "Term: mordio\n",
      "  DocID: 47, TF: 2\n",
      "Term: motiv\n",
      "  DocID: 27, TF: 2\n",
      "Term: moto\n",
      "  DocID: 25, TF: 2\n",
      "Term: move\n",
      "  DocID: 48, TF: 2\n",
      "Term: movin\n",
      "  DocID: 3, TF: 2\n",
      "Term: mucho\n",
      "  DocID: 47, TF: 4\n",
      "Term: muev\n",
      "  DocID: 45, TF: 2\n",
      "Term: muli\n",
      "  DocID: 1, TF: 2\n",
      "Term: mulona\n",
      "  DocID: 25, TF: 2\n",
      "Term: musica\n",
      "  DocID: 45, TF: 2\n",
      "Term: muy\n",
      "  DocID: 25, TF: 2\n",
      "Term: nabitawan\n",
      "  DocID: 1, TF: 2\n",
      "Term: nacer\n",
      "  DocID: 45, TF: 2\n",
      "Term: nada\n",
      "  DocID: 25, TF: 4\n",
      "Term: nakapagbigay\n",
      "  DocID: 1, TF: 8\n",
      "Term: nalgona\n",
      "  DocID: 25, TF: 2\n",
      "Term: nang\n",
      "  DocID: 1, TF: 2\n",
      "Term: napalingon\n",
      "  DocID: 1, TF: 2\n",
      "Term: navidad\n",
      "  DocID: 45, TF: 2\n",
      "Term: nazi\n",
      "  DocID: 45, TF: 2\n",
      "Term: necesito\n",
      "  DocID: 47, TF: 4\n",
      "Term: neck\n",
      "  DocID: 48, TF: 2\n",
      "Term: nena\n",
      "  DocID: 45, TF: 4\n",
      "Term: nesti\n",
      "  DocID: 45, TF: 2\n",
      "Term: ngiti\n",
      "  DocID: 1, TF: 8\n",
      "Term: nice\n",
      "  DocID: 48, TF: 2\n",
      "Term: nigga\n",
      "  DocID: 48, TF: 8\n",
      "Term: night\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 50, TF: 4\n",
      "Term: noch\n",
      "  DocID: 45, TF: 2\n",
      "Term: nosotro\n",
      "  DocID: 45, TF: 2\n",
      "Term: nuevament\n",
      "  DocID: 45, TF: 2\n",
      "Term: numb\n",
      "  DocID: 50, TF: 4\n",
      "Term: organizacin\n",
      "  DocID: 45, TF: 2\n",
      "Term: otro\n",
      "  DocID: 45, TF: 2\n",
      "Term: oye\n",
      "  DocID: 45, TF: 6\n",
      "Term: paid\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 27, TF: 2\n",
      "Term: palo\n",
      "  DocID: 45, TF: 2\n",
      "Term: pangarap\n",
      "  DocID: 1, TF: 12\n",
      "Term: pansin\n",
      "  DocID: 1, TF: 4\n",
      "Term: paqu\n",
      "  DocID: 25, TF: 2\n",
      "Term: park\n",
      "  DocID: 2, TF: 2\n",
      "  DocID: 3, TF: 2\n",
      "Term: parti\n",
      "  DocID: 45, TF: 2\n",
      "Term: pasin\n",
      "  DocID: 45, TF: 2\n",
      "Term: pass\n",
      "  DocID: 26, TF: 4\n",
      "  DocID: 27, TF: 2\n",
      "Term: passion\n",
      "  DocID: 27, TF: 2\n",
      "Term: paycat\n",
      "  DocID: 27, TF: 2\n",
      "Term: pegao\n",
      "  DocID: 45, TF: 56\n",
      "Term: pelo\n",
      "  DocID: 47, TF: 2\n",
      "Term: peng\n",
      "  DocID: 48, TF: 2\n",
      "Term: peopl\n",
      "  DocID: 27, TF: 2\n",
      "Term: perdi\n",
      "  DocID: 47, TF: 2\n",
      "Term: perfect\n",
      "  DocID: 27, TF: 2\n",
      "Term: permeat\n",
      "  DocID: 51, TF: 2\n",
      "Term: pero\n",
      "  DocID: 25, TF: 2\n",
      "  DocID: 45, TF: 4\n",
      "Term: phone\n",
      "  DocID: 48, TF: 2\n",
      "Term: pick\n",
      "  DocID: 48, TF: 2\n",
      "Term: pico\n",
      "  DocID: 45, TF: 2\n",
      "Term: pictur\n",
      "  DocID: 26, TF: 4\n",
      "Term: pig\n",
      "  DocID: 48, TF: 2\n",
      "Term: plastic\n",
      "  DocID: 27, TF: 2\n",
      "Term: plate\n",
      "  DocID: 48, TF: 2\n",
      "Term: play\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 26, TF: 4\n",
      "Term: plug\n",
      "  DocID: 48, TF: 2\n",
      "Term: poison\n",
      "  DocID: 3, TF: 42\n",
      "Term: por\n",
      "  DocID: 45, TF: 10\n",
      "Term: portion\n",
      "  DocID: 3, TF: 2\n",
      "Term: pour\n",
      "  DocID: 50, TF: 4\n",
      "Term: power\n",
      "  DocID: 3, TF: 2\n",
      "Term: preocupacion\n",
      "  DocID: 25, TF: 4\n",
      "Term: pro\n",
      "  DocID: 3, TF: 2\n",
      "Term: provoca\n",
      "  DocID: 45, TF: 4\n",
      "Term: pump\n",
      "  DocID: 50, TF: 4\n",
      "Term: quier\n",
      "  DocID: 25, TF: 4\n",
      "Term: quita\n",
      "  DocID: 45, TF: 6\n",
      "Term: rain\n",
      "  DocID: 26, TF: 8\n",
      "Term: rambo\n",
      "  DocID: 48, TF: 2\n",
      "Term: rankiao\n",
      "  DocID: 45, TF: 2\n",
      "Term: rap\n",
      "  DocID: 48, TF: 2\n",
      "Term: readi\n",
      "  DocID: 3, TF: 8\n",
      "Term: reaper\n",
      "  DocID: 51, TF: 2\n",
      "Term: redempt\n",
      "  DocID: 48, TF: 2\n",
      "Term: relationship\n",
      "  DocID: 3, TF: 2\n",
      "Term: remov\n",
      "  DocID: 50, TF: 4\n",
      "Term: rest\n",
      "  DocID: 3, TF: 2\n",
      "Term: return\n",
      "  DocID: 51, TF: 2\n",
      "Term: reverend\n",
      "  DocID: 48, TF: 2\n",
      "Term: roar\n",
      "  DocID: 26, TF: 4\n",
      "Term: rock\n",
      "  DocID: 26, TF: 16\n",
      "Term: rockin\n",
      "  DocID: 26, TF: 8\n",
      "Term: rodeando\n",
      "  DocID: 45, TF: 2\n",
      "Term: rojo\n",
      "  DocID: 45, TF: 2\n",
      "Term: ron\n",
      "  DocID: 3, TF: 2\n",
      "Term: ropa\n",
      "  DocID: 45, TF: 6\n",
      "Term: rrrrah\n",
      "  DocID: 25, TF: 2\n",
      "Term: ruin\n",
      "  DocID: 46, TF: 2\n",
      "Term: run\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 48, TF: 2\n",
      "Term: sabe\n",
      "  DocID: 45, TF: 2\n",
      "Term: sale\n",
      "  DocID: 25, TF: 2\n",
      "Term: salt\n",
      "  DocID: 45, TF: 2\n",
      "  DocID: 50, TF: 4\n",
      "Term: sana\n",
      "  DocID: 1, TF: 2\n",
      "Term: sandali\n",
      "  DocID: 1, TF: 4\n",
      "Term: sayin\n",
      "  DocID: 3, TF: 2\n",
      "Term: sayo\n",
      "  DocID: 1, TF: 2\n",
      "Term: scene\n",
      "  DocID: 26, TF: 4\n",
      "Term: schemin\n",
      "  DocID: 3, TF: 4\n",
      "Term: scream\n",
      "  DocID: 26, TF: 4\n",
      "Term: screamin\n",
      "  DocID: 3, TF: 2\n",
      "Term: secondhand\n",
      "  DocID: 26, TF: 4\n",
      "Term: sens\n",
      "  DocID: 3, TF: 2\n",
      "Term: shade\n",
      "  DocID: 49, TF: 4\n",
      "Term: shadow\n",
      "  DocID: 26, TF: 4\n",
      "Term: shake\n",
      "  DocID: 3, TF: 2\n",
      "Term: shock\n",
      "  DocID: 48, TF: 2\n",
      "Term: shop\n",
      "  DocID: 48, TF: 2\n",
      "Term: shot\n",
      "  DocID: 27, TF: 2\n",
      "Term: sient\n",
      "  DocID: 45, TF: 2\n",
      "Term: sientat\n",
      "  DocID: 25, TF: 2\n",
      "Term: sign\n",
      "  DocID: 2, TF: 2\n",
      "Term: sin\n",
      "  DocID: 25, TF: 4\n",
      "  DocID: 45, TF: 2\n",
      "Term: sing\n",
      "  DocID: 2, TF: 2\n",
      "Term: situat\n",
      "  DocID: 3, TF: 2\n",
      "Term: skate\n",
      "  DocID: 48, TF: 4\n",
      "Term: skatin\n",
      "  DocID: 48, TF: 2\n",
      "Term: skin\n",
      "  DocID: 49, TF: 8\n",
      "Term: skip\n",
      "  DocID: 49, TF: 4\n",
      "Term: sky\n",
      "  DocID: 2, TF: 2\n",
      "Term: slick\n",
      "  DocID: 3, TF: 2\n",
      "Term: slow\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 49, TF: 4\n",
      "Term: slung\n",
      "  DocID: 26, TF: 4\n",
      "Term: smile\n",
      "  DocID: 2, TF: 6\n",
      "  DocID: 3, TF: 2\n",
      "Term: snap\n",
      "  DocID: 48, TF: 2\n",
      "Term: sociedad\n",
      "  DocID: 45, TF: 4\n",
      "Term: soft\n",
      "  DocID: 2, TF: 4\n",
      "Term: sold\n",
      "  DocID: 26, TF: 4\n",
      "Term: spyderman\n",
      "  DocID: 3, TF: 2\n",
      "Term: stand\n",
      "  DocID: 26, TF: 4\n",
      "Term: star\n",
      "  DocID: 26, TF: 40\n",
      "Term: start\n",
      "  DocID: 3, TF: 4\n",
      "  DocID: 26, TF: 4\n",
      "Term: stay\n",
      "  DocID: 50, TF: 2\n",
      "Term: steal\n",
      "  DocID: 3, TF: 2\n",
      "Term: stood\n",
      "  DocID: 3, TF: 2\n",
      "Term: store\n",
      "  DocID: 26, TF: 4\n",
      "Term: stove\n",
      "  DocID: 27, TF: 2\n",
      "Term: straight\n",
      "  DocID: 51, TF: 2\n",
      "Term: strang\n",
      "  DocID: 3, TF: 2\n",
      "Term: string\n",
      "  DocID: 26, TF: 4\n",
      "Term: struggl\n",
      "  DocID: 48, TF: 2\n",
      "Term: stylish\n",
      "  DocID: 48, TF: 2\n",
      "Term: sun\n",
      "  DocID: 2, TF: 2\n",
      "Term: supplier\n",
      "  DocID: 50, TF: 4\n",
      "Term: ta\n",
      "  DocID: 26, TF: 12\n",
      "  DocID: 46, TF: 30\n",
      "  DocID: 48, TF: 2\n",
      "Term: takin\n",
      "  DocID: 3, TF: 2\n",
      "Term: talk\n",
      "  DocID: 48, TF: 2\n",
      "Term: tani\n",
      "  DocID: 45, TF: 2\n",
      "Term: tanong\n",
      "  DocID: 1, TF: 2\n",
      "Term: te\n",
      "  DocID: 25, TF: 6\n",
      "  DocID: 45, TF: 4\n",
      "Term: terreno\n",
      "  DocID: 47, TF: 2\n",
      "Term: ticket\n",
      "  DocID: 26, TF: 8\n",
      "Term: tiempo\n",
      "  DocID: 47, TF: 2\n",
      "Term: tien\n",
      "  DocID: 25, TF: 2\n",
      "Term: time\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 46, TF: 2\n",
      "Term: tingin\n",
      "  DocID: 1, TF: 2\n",
      "Term: tinig\n",
      "  DocID: 1, TF: 8\n",
      "Term: toca\n",
      "  DocID: 45, TF: 4\n",
      "Term: toco\n",
      "  DocID: 47, TF: 2\n",
      "Term: todo\n",
      "  DocID: 25, TF: 4\n",
      "Term: told\n",
      "  DocID: 48, TF: 2\n",
      "Term: tonight\n",
      "  DocID: 26, TF: 8\n",
      "Term: toqu\n",
      "  DocID: 47, TF: 2\n",
      "Term: totoo\n",
      "  DocID: 1, TF: 2\n",
      "Term: town\n",
      "  DocID: 26, TF: 4\n",
      "Term: tra\n",
      "  DocID: 45, TF: 6\n",
      "Term: trago\n",
      "  DocID: 25, TF: 2\n",
      "Term: trap\n",
      "  DocID: 48, TF: 4\n",
      "Term: tree\n",
      "  DocID: 2, TF: 4\n",
      "Term: tremendo\n",
      "  DocID: 25, TF: 4\n",
      "Term: trip\n",
      "  DocID: 26, TF: 4\n",
      "Term: trust\n",
      "  DocID: 3, TF: 2\n",
      "Term: tu\n",
      "  DocID: 25, TF: 6\n",
      "Term: tumbao\n",
      "  DocID: 45, TF: 2\n",
      "Term: tutugon\n",
      "  DocID: 1, TF: 2\n",
      "Term: uh\n",
      "  DocID: 3, TF: 2\n",
      "Term: ulit\n",
      "  DocID: 1, TF: 2\n",
      "Term: una\n",
      "  DocID: 25, TF: 2\n",
      "  DocID: 45, TF: 2\n",
      "Term: understand\n",
      "  DocID: 26, TF: 4\n",
      "Term: usa\n",
      "  DocID: 45, TF: 2\n",
      "Term: vacat\n",
      "  DocID: 27, TF: 2\n",
      "  DocID: 48, TF: 4\n",
      "Term: vacilon\n",
      "  DocID: 25, TF: 4\n",
      "Term: vamo\n",
      "  DocID: 25, TF: 8\n",
      "Term: vaquero\n",
      "  DocID: 45, TF: 2\n",
      "Term: vea\n",
      "  DocID: 25, TF: 2\n",
      "Term: vein\n",
      "  DocID: 50, TF: 4\n",
      "Term: veo\n",
      "  DocID: 25, TF: 12\n",
      "Term: victor\n",
      "  DocID: 45, TF: 2\n",
      "Term: vid\n",
      "  DocID: 48, TF: 2\n",
      "Term: vida\n",
      "  DocID: 25, TF: 8\n",
      "Term: vien\n",
      "  DocID: 25, TF: 2\n",
      "Term: vivir\n",
      "  DocID: 25, TF: 8\n",
      "Term: volviendo\n",
      "  DocID: 45, TF: 2\n",
      "Term: vos\n",
      "  DocID: 45, TF: 2\n",
      "Term: voto\n",
      "  DocID: 25, TF: 2\n",
      "Term: vuelv\n",
      "  DocID: 45, TF: 4\n",
      "Term: waist\n",
      "  DocID: 48, TF: 2\n",
      "Term: walk\n",
      "  DocID: 51, TF: 2\n",
      "Term: wall\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 26, TF: 4\n",
      "Term: wan\n",
      "  DocID: 46, TF: 2\n",
      "  DocID: 48, TF: 2\n",
      "  DocID: 49, TF: 48\n",
      "  DocID: 50, TF: 4\n",
      "Term: warn\n",
      "  DocID: 3, TF: 2\n",
      "Term: wave\n",
      "  DocID: 49, TF: 4\n",
      "Term: west\n",
      "  DocID: 48, TF: 2\n",
      "Term: whisper\n",
      "  DocID: 49, TF: 4\n",
      "Term: wife\n",
      "  DocID: 48, TF: 2\n",
      "Term: wind\n",
      "  DocID: 2, TF: 2\n",
      "Term: winner\n",
      "  DocID: 3, TF: 2\n",
      "  DocID: 48, TF: 2\n",
      "Term: wire\n",
      "  DocID: 50, TF: 4\n",
      "Term: woah\n",
      "  DocID: 26, TF: 4\n",
      "Term: worri\n",
      "  DocID: 46, TF: 2\n",
      "Term: worst\n",
      "  DocID: 49, TF: 4\n",
      "Term: worth\n",
      "  DocID: 49, TF: 24\n",
      "Term: wound\n",
      "  DocID: 50, TF: 4\n",
      "Term: wrong\n",
      "  DocID: 3, TF: 2\n",
      "Term: ya\n",
      "  DocID: 45, TF: 2\n",
      "Term: yandel\n",
      "  DocID: 45, TF: 6\n",
      "Term: yata\n",
      "  DocID: 1, TF: 2\n",
      "Term: yeah\n",
      "  DocID: 3, TF: 4\n",
      "  DocID: 25, TF: 2\n",
      "  DocID: 26, TF: 8\n",
      "  DocID: 27, TF: 2\n",
      "Term: yo\n",
      "  DocID: 25, TF: 8\n",
      "  DocID: 45, TF: 8\n",
      "  DocID: 47, TF: 4\n",
      "Term: youngen\n",
      "  DocID: 48, TF: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def print_full_index(index_dir):\n",
    "    full_index = {}\n",
    "\n",
    "    # Recorremos los archivos de los bloques fusionados en la carpeta\n",
    "    files = sorted(os.listdir(index_dir))\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):  # Asegurarnos de que es un archivo pickle\n",
    "            block_path = os.path.join(index_dir, file)\n",
    "\n",
    "            # Abrimos el archivo pickle y cargamos el bloque\n",
    "            with open(block_path, \"rb\") as f:\n",
    "                block = pickle.load(f)\n",
    "                \n",
    "                # Fusionamos los términos de este bloque con el índice completo\n",
    "                for term, postings in block.items():\n",
    "                    if term not in full_index:\n",
    "                        full_index[term] = postings\n",
    "                    else:\n",
    "                        # Si el término ya existe, combinamos las frecuencias de los docID\n",
    "                        for doc_id, freq in postings.items():\n",
    "                            if doc_id in full_index[term]:\n",
    "                                full_index[term][doc_id] += freq\n",
    "                            else:\n",
    "                                full_index[term][doc_id] = freq\n",
    "\n",
    "    # Ahora 'full_index' contiene todos los términos y sus frecuencias\n",
    "    # Puedes imprimirlo o retornar el diccionario completo\n",
    "    for term, postings in full_index.items():\n",
    "        print(f\"Term: {term}\")\n",
    "        for doc_id, freq in postings.items():\n",
    "            print(f\"  DocID: {doc_id}, TF: {freq}\")\n",
    "\n",
    "    return full_index\n",
    "\n",
    "full_index = print_full_index(s.index_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El índice no está ordenado en términos.\n",
      "Error: '6' aparece después de 'youngen'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def print_full_index_and_check_order(index_dir):\n",
    "    last_term = None  # Variable para verificar el orden de términos\n",
    "\n",
    "    # Recorremos los archivos de los bloques fusionados en la carpeta\n",
    "    files = sorted(os.listdir(index_dir))\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):  # Asegurarnos de que es un archivo pickle\n",
    "            block_path = os.path.join(index_dir, file)\n",
    "\n",
    "            # Abrimos el archivo pickle y cargamos el bloque\n",
    "            with open(block_path, \"rb\") as f:\n",
    "                block = pickle.load(f)\n",
    "                \n",
    "                # Verificar que los términos están en orden alfabético\n",
    "                for term in block.keys():\n",
    "                    if last_term is not None and term < last_term:\n",
    "                        print(\"El índice no está ordenado en términos.\")\n",
    "                        print(f\"Error: '{term}' aparece después de '{last_term}'\")\n",
    "                        return\n",
    "\n",
    "                    last_term = term  # Actualizar `last_term` para la siguiente comparación\n",
    "\n",
    "    print(\"El índice está ordenado en términos.\")\n",
    "\n",
    "# Ejecuta la función\n",
    "print_full_index_and_check_order(\"index_blocks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6': {2: 2}, 'aaa': {3: 2}, 'abr': {25: 2}, 'acaramelao': {45: 2}, 'acercarm': {47: 2}, 'acuerd': {45: 2}, 'adapta': {45: 2}, 'addict': {50: 4}, 'age': {48: 4}, 'ahh': {26: 8}, 'ain': {48: 14}, 'ake': {1: 2}, 'akin': {1: 8}, 'ako': {1: 4}, 'alam': {1: 4}, 'aliv': {2: 4, 26: 8}, 'aloca': {45: 4}, 'ang': {1: 14}, 'angel': {2: 6}, 'apretao': {45: 8}, 'apunta': {45: 2}, 'aqui': {25: 2}, 'argh': {45: 2}, 'armani': {45: 2}, 'arriba': {45: 24}, 'atentament': {45: 2}, 'avenida': {45: 2}, 'ay': {1: 10}, 'babe': {50: 4}, 'babi': {50: 2}, 'bacalao': {45: 2}, 'backstag': {26: 4}, 'bad': {48: 2}, 'bag': {48: 2}, 'baila': {45: 12}, 'bailando': {45: 4}, 'barb': {50: 4}, 'bawat': {1: 2}, 'beat': {26: 4, 49: 4}, 'beauti': {3: 2}, 'bell': {48: 2}, 'bench': {2: 2}, 'besot': {25: 2}, 'bet': {48: 2}, 'bewar': {3: 2}, 'bien': {45: 24}, 'bitch': {48: 2}, 'biv': {3: 2}, 'black': {48: 2}, 'blew': {26: 4}, 'blind': {3: 2}, 'blood': {50: 4}, 'blue': {2: 2}, 'blusa': {45: 2}, 'boca': {25: 2}, 'bodi': {45: 2}, 'boogi': {25: 2}, 'bought': {26: 4}, 'bound': {46: 6}, 'bout': {27: 2}, 'box': {26: 52}, 'boy': {48: 4}, 'break': {3: 2}, 'breakin': {3: 2}, 'breath': {48: 2}, 'bring': {49: 4}, 'brudda': {48: 2}, 'buck': {48: 2}, 'bumulong': {1: 2}, 'burn': {46: 12, 50: 4}, 'bus': {48: 2}, 'bust': {48: 2}, 'butt': {3: 2}, 'buzzin': {48: 2}, 'cab': {48: 2}, 'cachet': {45: 2}, 'cada': {45: 2}, 'calentarm': {47: 4}, 'call': {51: 2}, 'capitn': {45: 2}, 'care': {2: 2, 49: 12}, 'cash': {27: 2, 48: 4}, 'catch': {27: 2}, 'caught': {48: 2}, 'caution': {3: 2}, 'cerdito': {45: 2}, 'chainz': {27: 2}, 'chang': {26: 4}, 'checkin': {3: 2}, 'chest': {3: 2}, 'chick': {48: 2}, 'chose': {27: 2}, 'clockin': {3: 2}, 'close': {2: 2, 27: 4, 49: 8}, 'coco': {25: 2}, 'cold': {49: 4, 50: 34}, 'comin': {48: 2}, 'como': {45: 4}, 'conmigo': {45: 6}, 'controlando': {45: 2}, 'convers': {27: 2}, 'cook': {27: 2}, 'countri': {48: 6}, 'coupl': {46: 2}, 'crash': {27: 2}, 'creada': {45: 2}, 'crew': {3: 2}, 'crowd': {26: 4}, 'cruza': {45: 2}, 'cuando': {45: 14}, 'cuddl': {48: 2}, 'cunani': {45: 2}, 'cure': {3: 2}, 'cut': {3: 2, 50: 4}, 'cuttin': {48: 2}, 'dale': {25: 4}, 'dame': {25: 2}, 'danc': {2: 2}, 'darat': {1: 2}, 'dark': {27: 2, 51: 2}, 'date': {48: 6}, 'day': {26: 8, 50: 2}, 'dead': {3: 6}, 'death': {27: 2}, 'debajo': {45: 2}, 'deceiv': {46: 2}, 'deci': {25: 2}, 'del': {25: 2, 45: 4}, 'dem': {48: 2}, 'demon': {3: 2}, 'desir': {46: 6}, 'devo': {3: 2}, 'die': {27: 2, 46: 6}, 'dije': {47: 2}, 'dinero': {45: 2}, 'dinmico': {45: 2}, 'dipper': {48: 2}, 'distant': {26: 4}, 'ditch': {48: 2}, 'dito': {1: 2}, 'dmu': {48: 2}, 'door': {26: 4}, 'dos': {45: 2}, 'doubt': {51: 2}, 'downpour': {26: 4}, 'dreamin': {3: 2}, 'drive': {3: 2}, 'drivin': {3: 2}, 'duck': {48: 4}, 'duo': {45: 2}, 'ear': {26: 4}, 'easi': {46: 2}, 'edg': {50: 4}, 'ehh': {45: 8}, 'el': {45: 26, 47: 2}, 'ella': {25: 6, 45: 22, 47: 2}, 'em': {3: 2}, 'emborracha': {45: 2}, 'emot': {49: 4}, 'empezo': {47: 2}, 'empolvao': {45: 2}, 'en': {45: 6, 47: 2}, 'encanta': {45: 2}, 'encima': {45: 4}, 'ere': {25: 2}, 'eso': {45: 4}, 'espacio': {47: 2}, 'eye': {3: 2, 26: 40, 27: 6}, 'faith': {51: 2}, 'fall': {3: 2, 46: 2, 51: 2}, 'fam': {27: 2}, 'fantica': {45: 2}, 'fast': {49: 4}, 'fear': {27: 4}, 'fed': {48: 4}, 'feel': {2: 4, 49: 12, 50: 76}, 'feet': {50: 2}, 'fella': {3: 2}, 'fellow': {3: 2}, 'fenc': {2: 2}, 'fiesta': {25: 2}, 'fill': {48: 2}, 'fine': {45: 2}, 'flame': {46: 12}, 'fli': {3: 4}, 'flood': {48: 6}, 'foreign': {48: 2}, 'forget': {49: 12}, 'freez': {3: 2}, 'friday': {48: 4}, 'fro': {3: 2}, 'frontiando': {45: 2}, 'frontua': {45: 2}, 'fuck': {50: 2}, 'funki': {48: 4}, 'funni': {46: 2}, 'game': {48: 2}, 'ganandom': {47: 2}, 'gand': {48: 2}, 'gawin': {1: 2}, 'gettin': {3: 2, 27: 2}, 'gift': {48: 2}, 'girl': {3: 10, 27: 2, 48: 8, 50: 4}, 'gman': {48: 2}, 'god': {27: 2}, 'gon': {26: 12, 27: 2, 46: 12, 49: 48}, 'grito': {45: 4}, 'ground': {50: 2}, 'grow': {50: 2}, 'guaraguao': {45: 2}, 'guill': {45: 12}, 'guin': {45: 2}, 'guitar': {26: 24}, 'gunshot': {27: 2}, 'gyal': {48: 2}, 'hace': {25: 4}, 'haciendo': {45: 2}, 'hah': {25: 4}, 'hand': {2: 2, 26: 4, 48: 8}, 'hanggang': {1: 2}, 'hangin': {1: 2}, 'hard': {3: 2}, 'harrod': {48: 2}, 'hate': {48: 4}, 'head': {3: 2, 26: 4}, 'heard': {26: 8}, 'heart': {3: 4, 46: 2, 49: 4, 50: 6}, 'heavi': {26: 4}, 'hero': {26: 52}, 'hey': {2: 4}, 'high': {3: 2}, 'hill': {49: 8}, 'hindi': {1: 4}, 'historia': {45: 2}, 'hmpheard': {48: 2}, 'hmu': {48: 2}, 'hmv': {48: 2}, 'ho': {3: 2}, 'hoe': {3: 2}, 'hold': {48: 4, 50: 2}, 'hoo': {3: 2}, 'hot': {49: 4}, 'hous': {3: 2}, 'huh': {3: 4}, 'hung': {26: 4}, 'hurt': {49: 12}, 'ic': {48: 2}, 'ic3': {48: 2}, 'ika': {1: 2}, 'ikaw': {1: 2}, 'intent': {49: 4}, 'interesant': {45: 2}, 'interior': {45: 2}, 'isang': {1: 4}, 'ito': {1: 2}, 'iyong': {1: 8}, 'jajaja': {45: 2}, 'jala': {45: 2}, 'judg': {27: 2}, 'jugo': {47: 2}, 'juke': {26: 52}, 'jump': {2: 2, 50: 4}, 'ka': {1: 10}, 'kailan': {1: 2}, 'kay': {1: 8}, 'kaya': {1: 4}, 'keepin': {3: 2}, 'khalifa': {27: 2}, 'kiss': {2: 6, 3: 2, 27: 2}, 'know': {2: 2}, 'ko': {1: 6}, 'kong': {1: 2}, 'kung': {1: 2}, 'labio': {47: 2}, 'laid': {3: 2}, 'lalo': {45: 2}, 'lamig': {1: 8}, 'lang': {1: 6}, 'langit': {1: 2}, 'las': {45: 4}, 'latino': {45: 2}, 'laugh': {2: 2}, 'lay': {3: 2}, 'le': {45: 24, 47: 2}, 'left': {48: 4}, 'leg': {48: 2}, 'lejito': {45: 2}, 'lengua': {25: 4}, 'levanta': {45: 2}, 'liar': {50: 4}, 'libro': {45: 2}, 'lie': {46: 2}, 'life': {26: 4, 27: 2, 50: 6}, 'light': {51: 2}, 'lilingon': {1: 2}, 'linda': {45: 4}, 'lip': {2: 2}, 'live': {48: 2, 50: 4}, 'llega': {45: 2}, 'lo': {45: 20}, 'loca': {25: 2, 45: 4}, 'lone': {2: 2}, 'lookin': {3: 2}, 'los': {45: 4, 47: 2}, 'loser': {3: 2}, 'lot': {49: 12}, 'love': {2: 2, 3: 6, 46: 2, 49: 76, 50: 12}, 'low': {3: 2}, 'lucro': {45: 2}, 'mad': {48: 2}, 'mahn': {45: 6}, 'mahon': {45: 2}, 'main': {48: 2}, 'mami': {25: 4}, 'man2': {27: 2}, 'mandem': {48: 4}, 'mangarap': {1: 2}, 'manta': {45: 2}, 'maquilla': {45: 4}, 'maranta': {45: 2}, 'marat': {1: 2}, 'masa': {45: 2}, 'matando': {45: 2}, 'medio': {45: 2}, 'meet': {3: 2}, 'mellow': {3: 2}, 'meten': {45: 2}, 'mga': {1: 10}, 'mi': {25: 4, 45: 4}, 'midnight': {2: 2}, 'mind': {3: 6}, 'minsan': {1: 2}, 'mire': {47: 2}, 'miro': {47: 2}, 'missus': {48: 2}, 'modela': {45: 4}, 'money': {3: 2, 27: 4, 48: 2}, 'mong': {1: 8}, 'mordio': {47: 2}, 'motiv': {27: 2}, 'moto': {25: 2}, 'move': {48: 2}, 'movin': {3: 2}, 'mucho': {47: 4}, 'muev': {45: 2}, 'muli': {1: 2}, 'mulona': {25: 2}, 'musica': {45: 2}, 'muy': {25: 2}, 'nabitawan': {1: 2}, 'nacer': {45: 2}, 'nada': {25: 4}, 'nakapagbigay': {1: 8}, 'nalgona': {25: 2}, 'nang': {1: 2}, 'napalingon': {1: 2}, 'navidad': {45: 2}, 'nazi': {45: 2}, 'necesito': {47: 4}, 'neck': {48: 2}, 'nena': {45: 4}, 'nesti': {45: 2}, 'ngiti': {1: 8}, 'nice': {48: 2}, 'nigga': {48: 8}, 'night': {3: 2, 50: 4}, 'noch': {45: 2}, 'nosotro': {45: 2}, 'nuevament': {45: 2}, 'numb': {50: 4}, 'organizacin': {45: 2}, 'otro': {45: 2}, 'oye': {45: 6}, 'paid': {3: 2, 27: 2}, 'palo': {45: 2}, 'pangarap': {1: 12}, 'pansin': {1: 4}, 'paqu': {25: 2}, 'park': {2: 2, 3: 2}, 'parti': {45: 2}, 'pasin': {45: 2}, 'pass': {26: 4, 27: 2}, 'passion': {27: 2}, 'paycat': {27: 2}, 'pegao': {45: 56}, 'pelo': {47: 2}, 'peng': {48: 2}, 'peopl': {27: 2}, 'perdi': {47: 2}, 'perfect': {27: 2}, 'permeat': {51: 2}, 'pero': {25: 2, 45: 4}, 'phone': {48: 2}, 'pick': {48: 2}, 'pico': {45: 2}, 'pictur': {26: 4}, 'pig': {48: 2}, 'plastic': {27: 2}, 'plate': {48: 2}, 'play': {3: 2, 26: 4}, 'plug': {48: 2}, 'poison': {3: 42}, 'por': {45: 10}, 'portion': {3: 2}, 'pour': {50: 4}, 'power': {3: 2}, 'preocupacion': {25: 4}, 'pro': {3: 2}, 'provoca': {45: 4}, 'pump': {50: 4}, 'quier': {25: 4}, 'quita': {45: 6}, 'rain': {26: 8}, 'rambo': {48: 2}, 'rankiao': {45: 2}, 'rap': {48: 2}, 'readi': {3: 8}, 'reaper': {51: 2}, 'redempt': {48: 2}, 'relationship': {3: 2}, 'remov': {50: 4}, 'rest': {3: 2}, 'return': {51: 2}, 'reverend': {48: 2}, 'roar': {26: 4}, 'rock': {26: 16}, 'rockin': {26: 8}, 'rodeando': {45: 2}, 'rojo': {45: 2}, 'ron': {3: 2}, 'ropa': {45: 6}, 'rrrrah': {25: 2}, 'ruin': {46: 2}, 'run': {3: 2, 48: 2}, 'sabe': {45: 2}, 'sale': {25: 2}, 'salt': {45: 2, 50: 4}, 'sana': {1: 2}, 'sandali': {1: 4}, 'sayin': {3: 2}, 'sayo': {1: 2}, 'scene': {26: 4}, 'schemin': {3: 4}, 'scream': {26: 4}, 'screamin': {3: 2}, 'secondhand': {26: 4}, 'sens': {3: 2}, 'shade': {49: 4}, 'shadow': {26: 4}, 'shake': {3: 2}, 'shock': {48: 2}, 'shop': {48: 2}, 'shot': {27: 2}, 'sient': {45: 2}, 'sientat': {25: 2}, 'sign': {2: 2}, 'sin': {25: 4, 45: 2}, 'sing': {2: 2}, 'situat': {3: 2}, 'skate': {48: 4}, 'skatin': {48: 2}, 'skin': {49: 8}, 'skip': {49: 4}, 'sky': {2: 2}, 'slick': {3: 2}, 'slow': {3: 2, 27: 2, 49: 4}, 'slung': {26: 4}, 'smile': {2: 6, 3: 2}, 'snap': {48: 2}, 'sociedad': {45: 4}, 'soft': {2: 4}, 'sold': {26: 4}, 'spyderman': {3: 2}, 'stand': {26: 4}, 'star': {26: 40}, 'start': {3: 4, 26: 4}, 'stay': {50: 2}, 'steal': {3: 2}, 'stood': {3: 2}, 'store': {26: 4}, 'stove': {27: 2}, 'straight': {51: 2}, 'strang': {3: 2}, 'string': {26: 4}, 'struggl': {48: 2}, 'stylish': {48: 2}, 'sun': {2: 2}, 'supplier': {50: 4}, 'ta': {26: 12, 46: 30, 48: 2}, 'takin': {3: 2}, 'talk': {48: 2}, 'tani': {45: 2}, 'tanong': {1: 2}, 'te': {25: 6, 45: 4}, 'terreno': {47: 2}, 'ticket': {26: 8}, 'tiempo': {47: 2}, 'tien': {25: 2}, 'time': {3: 2, 46: 2}, 'tingin': {1: 2}, 'tinig': {1: 8}, 'toca': {45: 4}, 'toco': {47: 2}, 'todo': {25: 4}, 'told': {48: 2}, 'tonight': {26: 8}, 'toqu': {47: 2}, 'totoo': {1: 2}, 'town': {26: 4}, 'tra': {45: 6}, 'trago': {25: 2}, 'trap': {48: 4}, 'tree': {2: 4}, 'tremendo': {25: 4}, 'trip': {26: 4}, 'trust': {3: 2}, 'tu': {25: 6}, 'tumbao': {45: 2}, 'tutugon': {1: 2}, 'uh': {3: 2}, 'ulit': {1: 2}, 'una': {25: 2, 45: 2}, 'understand': {26: 4}, 'usa': {45: 2}, 'vacat': {27: 2, 48: 4}, 'vacilon': {25: 4}, 'vamo': {25: 8}, 'vaquero': {45: 2}, 'vea': {25: 2}, 'vein': {50: 4}, 'veo': {25: 12}, 'victor': {45: 2}, 'vid': {48: 2}, 'vida': {25: 8}, 'vien': {25: 2}, 'vivir': {25: 8}, 'volviendo': {45: 2}, 'vos': {45: 2}, 'voto': {25: 2}, 'vuelv': {45: 4}, 'waist': {48: 2}, 'walk': {51: 2}, 'wall': {3: 2, 26: 4}, 'wan': {46: 2, 48: 2, 49: 48, 50: 4}, 'warn': {3: 2}, 'wave': {49: 4}, 'west': {48: 2}, 'whisper': {49: 4}, 'wife': {48: 2}, 'wind': {2: 2}, 'winner': {3: 2, 48: 2}, 'wire': {50: 4}, 'woah': {26: 4}, 'worri': {46: 2}, 'worst': {49: 4}, 'worth': {49: 24}, 'wound': {50: 4}, 'wrong': {3: 2}, 'ya': {45: 2}, 'yandel': {45: 6}, 'yata': {1: 2}, 'yeah': {3: 4, 25: 2, 26: 8, 27: 2}, 'yo': {25: 8, 45: 8, 47: 4}, 'youngen': {48: 2}}\n",
      "Top documentos más similares a la consulta:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def print_full_index(index_dir):\n",
    "    full_index = {}\n",
    "    files = sorted(os.listdir(index_dir))\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):  \n",
    "            block_path = os.path.join(index_dir, file)\n",
    "            with open(block_path, \"rb\") as f:\n",
    "                block = pickle.load(f)\n",
    "                \n",
    "                for term, postings in block.items():\n",
    "                    if term not in full_index:\n",
    "                        full_index[term] = postings\n",
    "                    else:\n",
    "                        for doc_id, freq in postings.items():\n",
    "                            if doc_id in full_index[term]:\n",
    "                                full_index[term][doc_id] += freq\n",
    "                            else:\n",
    "                                full_index[term][doc_id] = freq\n",
    "\n",
    "    return full_index\n",
    "\n",
    "def calculate_idf(full_index, total_docs):\n",
    "    idf = {}\n",
    "    for term, postings in full_index.items():\n",
    "        df = len(postings)\n",
    "        idf[term] = math.log(total_docs / df) if df > 0 else 0\n",
    "    return idf\n",
    "\n",
    "def calculate_tf_idf(tf, idf):\n",
    "    return tf * idf\n",
    "\n",
    "def cosine_score(query_terms, full_index, idf, length):\n",
    "    Scores = defaultdict(float)\n",
    "    Length = length\n",
    "\n",
    "    for t in query_terms:\n",
    "        if t not in idf:\n",
    "            continue\n",
    "\n",
    "        wt_q = idf[t]\n",
    "        postings = full_index.get(t, {})\n",
    "\n",
    "        for d, tf in postings.items():\n",
    "            wt_d = calculate_tf_idf(tf, idf[t])\n",
    "            Scores[d] += wt_d * wt_q\n",
    "\n",
    "    for d in Scores:\n",
    "        Scores[d] /= Length[d] if Length[d] != 0 else 1\n",
    "\n",
    "    K = 5\n",
    "    top_K = sorted(Scores.items(), key=lambda x: x[1], reverse=True)[:K]\n",
    "\n",
    "    return top_K\n",
    "\n",
    "# Calcular la longitud de cada documento\n",
    "def calculate_length(full_index, idf):\n",
    "    length = defaultdict(float)\n",
    "    for term, postings in full_index.items():\n",
    "        for doc_id, tf in postings.items():\n",
    "            tf_idf_value = calculate_tf_idf(tf, idf[term])\n",
    "            length[doc_id] += tf_idf_value ** 2\n",
    "\n",
    "    for doc_id in length:\n",
    "        length[doc_id] = math.sqrt(length[doc_id])\n",
    "\n",
    "    return length\n",
    "\n",
    "# Usar las funciones para calcular la similitud de coseno\n",
    "index_dir = \"index_blocks\"\n",
    "full_index = print_full_index(index_dir)\n",
    "print(full_index)\n",
    "total_docs = len({doc_id for postings in full_index.values() for doc_id in postings})\n",
    "idf = calculate_idf(full_index, total_docs)\n",
    "length = calculate_length(full_index, idf)\n",
    "\n",
    "# Consulta de ejemplo\n",
    "query_terms = [\"example\", \"terms\", \"for\", \"query\"]  \n",
    "query_terms = preprocesamiento(query_terms)\n",
    "\n",
    "# Calcular puntajes de coseno\n",
    "top_documents = cosine_score(query_terms, full_index, idf, length)\n",
    "\n",
    "print(\"Top documentos más similares a la consulta:\")\n",
    "for doc_id, score in top_documents:\n",
    "    print(f\"Documento {doc_id}: Similaridad de coseno = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
