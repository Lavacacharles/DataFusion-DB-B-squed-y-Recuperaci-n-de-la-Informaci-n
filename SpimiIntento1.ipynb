{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto jiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: packaging in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ce mar\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ce mar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ce mar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:177: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Ce\n",
      "[nltk_data]     mar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ce mar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Ce mar\\.cache\\kagglehub\\datasets\\imuhammad\\audio-features-and-lyrics-of-spotify-songs\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"imuhammad/audio-features-and-lyrics-of-spotify-songs\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords-en.txt\", encoding=\"latin1\") as file:\n",
    "    stoplist = [line.rstrip().lower() for line in file]\n",
    "\n",
    "def preprocesamiento(texto, stemming=True):\n",
    "  words = []\n",
    "  texto = texto.lower()\n",
    "  texto = re.sub(r'[^a-zA-Z0-9_À-ÿ]', ' ', texto)\n",
    "  # tokenizar\n",
    "  words = nltk.word_tokenize(texto, language='spanish')\n",
    "  # filtrar stopwords\n",
    "  words = [word for word in words if word not in stoplist]\n",
    "  # reducir palabras (stemming)\n",
    "  if stemming:\n",
    "      words = [stemmer.stem(word) for word in words]\n",
    "  return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ce mar\\.cache\\kagglehub\\datasets\\imuhammad\\audio-features-and-lyrics-of-spotify-songs\\versions\\1\\spotify_songs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track_id</td>\n",
       "      <td>track_name</td>\n",
       "      <td>track_artist</td>\n",
       "      <td>lyrics</td>\n",
       "      <td>track_popularity</td>\n",
       "      <td>track_album_id</td>\n",
       "      <td>track_album_name</td>\n",
       "      <td>track_album_release_date</td>\n",
       "      <td>playlist_name</td>\n",
       "      <td>playlist_id</td>\n",
       "      <td>...</td>\n",
       "      <td>loudness</td>\n",
       "      <td>mode</td>\n",
       "      <td>speechiness</td>\n",
       "      <td>acousticness</td>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>liveness</td>\n",
       "      <td>valence</td>\n",
       "      <td>tempo</td>\n",
       "      <td>duration_ms</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017A6SJgTbfQVU2EtsPNo</td>\n",
       "      <td>Pangarap</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>Minsan pa Nang ako'y napalingon Hindi ko alam ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1srJQ0njEQgd8w4XSqI4JQ</td>\n",
       "      <td>Trip</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>Pinoy Classic Rock</td>\n",
       "      <td>37i9dQZF1DWYDQ8wBxd7xt</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.5660000000000001</td>\n",
       "      <td>97.091</td>\n",
       "      <td>235440</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004s3t0ONYlzxII9PLgU6z</td>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>The trees, are singing in the wind The sky blu...</td>\n",
       "      <td>28</td>\n",
       "      <td>3z04Lb9Dsilqw68SHt6jLB</td>\n",
       "      <td>Love &amp; Loss</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>Hard Rock Workout</td>\n",
       "      <td>3YouF0u7waJnolytf9JCXf</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.34700000000000003</td>\n",
       "      <td>0.404</td>\n",
       "      <td>135.225</td>\n",
       "      <td>373512</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00chLpzhgVjxs1zKC9UScL</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>NA Yeah, Spyderman and Freeze in full effect U...</td>\n",
       "      <td>0</td>\n",
       "      <td>6oZ6brjB8x3GoeSYdwJdPc</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>Back in the day - R&amp;B, New Jack Swing, Swingbe...</td>\n",
       "      <td>3a9y4eeCJRmG9p4YKfqYIx</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21600000000000005</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.007229999999999999</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.65</td>\n",
       "      <td>111.904</td>\n",
       "      <td>262467</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00cqd6ZsSkLZqGMlQCR0Zo</td>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>I really can't stay Baby it's cold outside I'v...</td>\n",
       "      <td>41</td>\n",
       "      <td>3ssspRe42CXkhPxdc12xcp</td>\n",
       "      <td>CeeLo's Magic Moment</td>\n",
       "      <td>2012-10-29</td>\n",
       "      <td>Christmas Soul</td>\n",
       "      <td>6FZYc2BvF7tColxO8PBShV</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.6890000000000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>118.593</td>\n",
       "      <td>243067</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                                                  1   \\\n",
       "0                track_id                                         track_name   \n",
       "1  0017A6SJgTbfQVU2EtsPNo                                           Pangarap   \n",
       "2  004s3t0ONYlzxII9PLgU6z                                       I Feel Alive   \n",
       "3  00chLpzhgVjxs1zKC9UScL                                             Poison   \n",
       "4  00cqd6ZsSkLZqGMlQCR0Zo  Baby It's Cold Outside (feat. Christina Aguilera)   \n",
       "\n",
       "                2                                                  3   \\\n",
       "0     track_artist                                             lyrics   \n",
       "1  Barbie's Cradle  Minsan pa Nang ako'y napalingon Hindi ko alam ...   \n",
       "2    Steady Rollin  The trees, are singing in the wind The sky blu...   \n",
       "3   Bell Biv DeVoe  NA Yeah, Spyderman and Freeze in full effect U...   \n",
       "4      CeeLo Green  I really can't stay Baby it's cold outside I'v...   \n",
       "\n",
       "                 4                       5                     6   \\\n",
       "0  track_popularity          track_album_id      track_album_name   \n",
       "1                41  1srJQ0njEQgd8w4XSqI4JQ                  Trip   \n",
       "2                28  3z04Lb9Dsilqw68SHt6jLB           Love & Loss   \n",
       "3                 0  6oZ6brjB8x3GoeSYdwJdPc                  Gold   \n",
       "4                41  3ssspRe42CXkhPxdc12xcp  CeeLo's Magic Moment   \n",
       "\n",
       "                         7   \\\n",
       "0  track_album_release_date   \n",
       "1                2001-01-01   \n",
       "2                2017-11-21   \n",
       "3                2005-01-01   \n",
       "4                2012-10-29   \n",
       "\n",
       "                                                  8                       9   \\\n",
       "0                                      playlist_name             playlist_id   \n",
       "1                                 Pinoy Classic Rock  37i9dQZF1DWYDQ8wBxd7xt   \n",
       "2                                  Hard Rock Workout  3YouF0u7waJnolytf9JCXf   \n",
       "3  Back in the day - R&B, New Jack Swing, Swingbe...  3a9y4eeCJRmG9p4YKfqYIx   \n",
       "4                                     Christmas Soul  6FZYc2BvF7tColxO8PBShV   \n",
       "\n",
       "   ...        15    16                   17                  18  \\\n",
       "0  ...  loudness  mode          speechiness        acousticness   \n",
       "1  ...   -10.068     1               0.0236               0.279   \n",
       "2  ...    -4.739     1               0.0442              0.0117   \n",
       "3  ...    -7.504     0  0.21600000000000005             0.00432   \n",
       "4  ...    -5.819     0               0.0341  0.6890000000000001   \n",
       "\n",
       "                     19                   20                  21       22  \\\n",
       "0      instrumentalness             liveness             valence    tempo   \n",
       "1                0.0117               0.0887  0.5660000000000001   97.091   \n",
       "2               0.00994  0.34700000000000003               0.404  135.225   \n",
       "3  0.007229999999999999                0.489                0.65  111.904   \n",
       "4                     0               0.0664               0.405  118.593   \n",
       "\n",
       "            23        24  \n",
       "0  duration_ms  language  \n",
       "1       235440        tl  \n",
       "2       373512        en  \n",
       "3       262467        en  \n",
       "4       243067        en  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = os.listdir(path)\n",
    "songs = os.path.join(path, list[0])\n",
    "print(songs)\n",
    "dataset = pd.read_csv(songs, header=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really can't stay Baby it's cold outside I've got to go away Baby it's cold out there This evening has been Been hoping that you'd drop in So very nice I'll hold your hands, they're just like ice My mother will start to worry Beautiful, what's your hurry? My father will be pacing the floor Listen to that fireplace roar So really I'd better scurry Beautiful, please don't hurry Well maybe just a half a drink more Why don't you put some records on while I pour The neighbors might think Baby, it's bad out there Say, what's in this drink? No cabs to be had out there I wish I knew how Your eyes are like starlight To break the spell I'll take your hat, your hair looks swell I ought to say no, no, no, sir Mind if I move in closer? At least I'm gonna say that I tried What's the sense in hurting my pride? I really can't stay Baby don't hold out Baby it's cold outside I simply must go See that it's cold outside The answer is no I said it's cold out there This welcome has been How lucky that you dropped in So nice and warm Look out the window at that storm My sister will be suspicious Gosh, your lips look delicious My brother will be there at the door Waves upon a tropical shore My maiden aunt's mind is vicious Oh, your lips are delicious Maybe just a cigarette more Never such a blizzard before Hey I've got to go home Baby, you'll freeze out there Say, lend me your coat It's up to your knees out there You've really been grand I'm thrilled when you touch my hand But don't you see How can you do this thing to me? There's bound to be talk tomorrow Think of my life long sorrow At least there will be plenty implied If you caught pneumonia and died I really can't stay Get over that old lie Baby, baby it's cold outside\n"
     ]
    }
   ],
   "source": [
    "fila_5 = dataset.iloc[4, 3]\n",
    "print(fila_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "\n",
    "class InvertIndex:\n",
    "    def __init__(self, index_file):\n",
    "        self.index_file = index_file\n",
    "        self.index = {}\n",
    "        self.idf = {}\n",
    "        self.length = {}\n",
    "\n",
    "    def building(self, collection_text, position_text):\n",
    "        total_docs = len(collection_text)\n",
    "        doc_count = {}\n",
    "\n",
    "        # build the inverted index with the collection\n",
    "        for i, row in collection_text.iterrows():\n",
    "          doc_id = i\n",
    "          doc = row.iloc[position_text]\n",
    "          keywords = preprocesamiento(doc)\n",
    "        # compute the tf\n",
    "          tf_per_doc = {}\n",
    "\n",
    "          for keyword in keywords:\n",
    "            if keyword in tf_per_doc:\n",
    "              tf_per_doc[keyword] += 1\n",
    "            else:\n",
    "              tf_per_doc[keyword] = 1\n",
    "          for term in tf_per_doc:\n",
    "            tf_per_doc[term] = math.log10(1 + tf_per_doc[term])\n",
    "\n",
    "        # compute the idf\n",
    "          for term, tf in tf_per_doc.items():\n",
    "            if term not in self.index:\n",
    "                self.index[term] = []\n",
    "            self.index[term].append((doc_id, tf))\n",
    "\n",
    "            if term in doc_count:\n",
    "                doc_count[term] += 1\n",
    "            else:\n",
    "                doc_count[term] = 1\n",
    "\n",
    "        for term, count in doc_count.items():\n",
    "            self.idf[term] = math.log(total_docs / (count))\n",
    "        # compute the length (norm)\n",
    "        for doc_id in range(total_docs):\n",
    "            norm = 0\n",
    "            for term, postings in self.index.items():\n",
    "                for doc, tf in postings:\n",
    "                    if doc == doc_id:\n",
    "                        norm += (tf * self.idf[term]) ** 2\n",
    "            self.length[doc_id] = math.sqrt(norm) #Get sum(tf*idf^2)\n",
    "        # store in disk\n",
    "        with open(self.index_file, 'wb') as f:\n",
    "            pickle.dump((self.index, self.idf, self.length), f)\n",
    "\n",
    "    def retrieval(self, query, k):\n",
    "        self.load_index()\n",
    "        N = len(self.length)\n",
    "        scores = [0] * len(self.length)\n",
    "        # preprocesar la query: extraer los terminos unicos\n",
    "        terms = preprocesamiento(query)\n",
    "        # calcular el tf-idf del query\n",
    "        tf_query = {}\n",
    "        for term in terms:\n",
    "            if term in tf_query:\n",
    "                tf_query[term] += 1\n",
    "            else:\n",
    "                tf_query[term] = 1\n",
    "        tfidf_query = {}\n",
    "        for term, tf in tf_query.items():   \n",
    "            if term in self.idf:\n",
    "                tfidf_query[term] = math.log10(1 + tf) * self.idf[term]\n",
    "\n",
    "        norm_query = math.sqrt(sum(w_tq**2 for w_tq in tfidf_query.values()))\n",
    "\n",
    "        # aplicar similitud de coseno y guardarlo en el diccionario score\n",
    "        for term, w_tq in tfidf_query.items():\n",
    "            if term in self.index:\n",
    "                for doc, tf_td in self.index[term]:\n",
    "                    w_td = tf_td * self.idf[term] #Calculo tf_idf para wt,d\n",
    "                    scores[doc] += w_td * w_tq\n",
    "                    \n",
    "        for d in range(N):\n",
    "            if self.length[d] != 0:\n",
    "                scores[d] /= self.length[d]*norm_query  # Normalización del documento y la consulta\n",
    "    \n",
    "        # ordenar el score de forma descendente\n",
    "        result = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        # retornamos los k documentos mas relevantes (de mayor similitud al query)\n",
    "        return result[:k]\n",
    "\n",
    "    def load_index(self):\n",
    "        # load index from disk\n",
    "        with open(self.index_file, 'rb') as f:\n",
    "            self.index, self.idf, self.length = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.head(40)\n",
    "\n",
    "# def mostrarDocumentos(result):\n",
    "#     for doc, score in result:\n",
    "#         print(\"Documento\", doc, \" con similitud: \", score)\n",
    "#     print(\"_____\")\n",
    "\n",
    "# index = InvertIndex(\"indice.dat\")\n",
    "# index.building(dataset, 3) #El texto a procesar esta en la posicion 1\n",
    "\n",
    "# Query1 = \"I really can't stay Baby it's cold outside \"\n",
    "# result = index.retrieval(Query1, 10)\n",
    "# print(\"Resultados para\", Query1)\n",
    "# mostrarDocumentos(result)\n",
    "\n",
    "# news_value = dataset.iloc[4, 3] # Sacamos el primer doc el cual nos deberia de dar 1\n",
    "# Query2 = news_value\n",
    "# result2 = index.retrieval(Query2, 10)\n",
    "# print(\"Resultados para\", Query2)\n",
    "# mostrarDocumentos(result2)\n",
    "\n",
    "# Query3 = dataset.iloc[7, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "# Query3 = dataset.iloc[20, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "# Query3 = dataset.iloc[19, 3]\n",
    "# result3 = index.retrieval(Query3, 10)\n",
    "# print(\"Resultados para\", Query3)\n",
    "# mostrarDocumentos(result3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>minsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>napalingon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>39</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>39</td>\n",
       "      <td>santa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6908</th>\n",
       "      <td>39</td>\n",
       "      <td>claus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>39</td>\n",
       "      <td>comin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>39</td>\n",
       "      <td>town</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index ProcessedText\n",
       "0         1        minsan\n",
       "1         1          nang\n",
       "2         1           ako\n",
       "3         1    napalingon\n",
       "4         1         hindi\n",
       "...     ...           ...\n",
       "6906     39          town\n",
       "6907     39         santa\n",
       "6908     39         claus\n",
       "6909     39         comin\n",
       "6910     39          town\n",
       "\n",
       "[6911 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.head(40)\n",
    "\n",
    "#Procesar los documentos en pares\n",
    "position_text=3\n",
    "pairs = []\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    if(i!=0):\n",
    "        words = preprocesamiento(row.iloc[position_text])\n",
    "        for text in words:\n",
    "            pairs.append((i, text))\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs, columns=['Index', 'ProcessedText'])\n",
    "pairs_df.head(len(pairs_df))\n",
    "\n",
    "# print(pairs_df[pairs_df[\"ProcessedText\"] == \"6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_0.pkl\n",
      "block_1.pkl\n",
      "block_10.pkl\n",
      "block_100.pkl\n",
      "block_101.pkl\n",
      "block_102.pkl\n",
      "block_103.pkl\n",
      "block_104.pkl\n",
      "block_105.pkl\n",
      "block_106.pkl\n",
      "block_107.pkl\n",
      "block_108.pkl\n",
      "block_109.pkl\n",
      "block_11.pkl\n",
      "block_110.pkl\n",
      "block_111.pkl\n",
      "block_112.pkl\n",
      "block_113.pkl\n",
      "block_114.pkl\n",
      "block_115.pkl\n",
      "block_116.pkl\n",
      "block_117.pkl\n",
      "block_118.pkl\n",
      "block_119.pkl\n",
      "block_12.pkl\n",
      "block_120.pkl\n",
      "block_121.pkl\n",
      "block_122.pkl\n",
      "block_123.pkl\n",
      "block_124.pkl\n",
      "block_125.pkl\n",
      "block_126.pkl\n",
      "block_127.pkl\n",
      "block_128.pkl\n",
      "block_129.pkl\n",
      "block_13.pkl\n",
      "block_130.pkl\n",
      "block_131.pkl\n",
      "block_132.pkl\n",
      "block_133.pkl\n",
      "block_134.pkl\n",
      "block_135.pkl\n",
      "block_136.pkl\n",
      "block_137.pkl\n",
      "block_138.pkl\n",
      "block_139.pkl\n",
      "block_14.pkl\n",
      "block_140.pkl\n",
      "block_141.pkl\n",
      "block_142.pkl\n",
      "block_143.pkl\n",
      "block_144.pkl\n",
      "block_145.pkl\n",
      "block_146.pkl\n",
      "block_147.pkl\n",
      "block_148.pkl\n",
      "block_149.pkl\n",
      "block_15.pkl\n",
      "block_150.pkl\n",
      "block_151.pkl\n",
      "block_152.pkl\n",
      "block_153.pkl\n",
      "block_154.pkl\n",
      "block_155.pkl\n",
      "block_156.pkl\n",
      "block_157.pkl\n",
      "block_158.pkl\n",
      "block_159.pkl\n",
      "block_16.pkl\n",
      "block_160.pkl\n",
      "block_161.pkl\n",
      "block_162.pkl\n",
      "block_163.pkl\n",
      "block_164.pkl\n",
      "block_165.pkl\n",
      "block_166.pkl\n",
      "block_167.pkl\n",
      "block_168.pkl\n",
      "block_169.pkl\n",
      "block_17.pkl\n",
      "block_170.pkl\n",
      "block_171.pkl\n",
      "block_172.pkl\n",
      "block_173.pkl\n",
      "block_174.pkl\n",
      "block_175.pkl\n",
      "block_176.pkl\n",
      "block_177.pkl\n",
      "block_178.pkl\n",
      "block_179.pkl\n",
      "block_18.pkl\n",
      "block_180.pkl\n",
      "block_181.pkl\n",
      "block_182.pkl\n",
      "block_183.pkl\n",
      "block_184.pkl\n",
      "block_185.pkl\n",
      "block_186.pkl\n",
      "block_187.pkl\n",
      "block_188.pkl\n",
      "block_189.pkl\n",
      "block_19.pkl\n",
      "block_190.pkl\n",
      "block_191.pkl\n",
      "block_192.pkl\n",
      "block_193.pkl\n",
      "block_194.pkl\n",
      "block_195.pkl\n",
      "block_196.pkl\n",
      "block_197.pkl\n",
      "block_198.pkl\n",
      "block_199.pkl\n",
      "block_2.pkl\n",
      "block_20.pkl\n",
      "block_200.pkl\n",
      "block_201.pkl\n",
      "block_202.pkl\n",
      "block_203.pkl\n",
      "block_204.pkl\n",
      "block_205.pkl\n",
      "block_206.pkl\n",
      "block_207.pkl\n",
      "block_208.pkl\n",
      "block_209.pkl\n",
      "block_21.pkl\n",
      "block_210.pkl\n",
      "block_211.pkl\n",
      "block_212.pkl\n",
      "block_213.pkl\n",
      "block_214.pkl\n",
      "block_215.pkl\n",
      "block_216.pkl\n",
      "block_217.pkl\n",
      "block_218.pkl\n",
      "block_219.pkl\n",
      "block_22.pkl\n",
      "block_220.pkl\n",
      "block_221.pkl\n",
      "block_222.pkl\n",
      "block_223.pkl\n",
      "block_224.pkl\n",
      "block_225.pkl\n",
      "block_226.pkl\n",
      "block_227.pkl\n",
      "block_228.pkl\n",
      "block_229.pkl\n",
      "block_23.pkl\n",
      "block_230.pkl\n",
      "block_231.pkl\n",
      "block_232.pkl\n",
      "block_233.pkl\n",
      "block_234.pkl\n",
      "block_235.pkl\n",
      "block_236.pkl\n",
      "block_237.pkl\n",
      "block_238.pkl\n",
      "block_239.pkl\n",
      "block_24.pkl\n",
      "block_240.pkl\n",
      "block_241.pkl\n",
      "block_242.pkl\n",
      "block_243.pkl\n",
      "block_244.pkl\n",
      "block_245.pkl\n",
      "block_246.pkl\n",
      "block_247.pkl\n",
      "block_248.pkl\n",
      "block_249.pkl\n",
      "block_25.pkl\n",
      "block_250.pkl\n",
      "block_251.pkl\n",
      "block_252.pkl\n",
      "block_253.pkl\n",
      "block_254.pkl\n",
      "block_255.pkl\n",
      "block_256.pkl\n",
      "block_257.pkl\n",
      "block_258.pkl\n",
      "block_259.pkl\n",
      "block_26.pkl\n",
      "block_260.pkl\n",
      "block_261.pkl\n",
      "block_262.pkl\n",
      "block_263.pkl\n",
      "block_264.pkl\n",
      "block_265.pkl\n",
      "block_266.pkl\n",
      "block_267.pkl\n",
      "block_268.pkl\n",
      "block_269.pkl\n",
      "block_27.pkl\n",
      "block_270.pkl\n",
      "block_271.pkl\n",
      "block_272.pkl\n",
      "block_273.pkl\n",
      "block_274.pkl\n",
      "block_275.pkl\n",
      "block_276.pkl\n",
      "block_277.pkl\n",
      "block_278.pkl\n",
      "block_279.pkl\n",
      "block_28.pkl\n",
      "block_280.pkl\n",
      "block_281.pkl\n",
      "block_282.pkl\n",
      "block_283.pkl\n",
      "block_284.pkl\n",
      "block_285.pkl\n",
      "block_286.pkl\n",
      "block_287.pkl\n",
      "block_288.pkl\n",
      "block_289.pkl\n",
      "block_29.pkl\n",
      "block_290.pkl\n",
      "block_291.pkl\n",
      "block_292.pkl\n",
      "block_293.pkl\n",
      "block_294.pkl\n",
      "block_295.pkl\n",
      "block_296.pkl\n",
      "block_297.pkl\n",
      "block_298.pkl\n",
      "block_299.pkl\n",
      "block_3.pkl\n",
      "block_30.pkl\n",
      "block_300.pkl\n",
      "block_301.pkl\n",
      "block_302.pkl\n",
      "block_303.pkl\n",
      "block_304.pkl\n",
      "block_305.pkl\n",
      "block_306.pkl\n",
      "block_307.pkl\n",
      "block_308.pkl\n",
      "block_309.pkl\n",
      "block_31.pkl\n",
      "block_310.pkl\n",
      "block_311.pkl\n",
      "block_312.pkl\n",
      "block_313.pkl\n",
      "block_314.pkl\n",
      "block_315.pkl\n",
      "block_316.pkl\n",
      "block_317.pkl\n",
      "block_318.pkl\n",
      "block_319.pkl\n",
      "block_32.pkl\n",
      "block_320.pkl\n",
      "block_321.pkl\n",
      "block_322.pkl\n",
      "block_323.pkl\n",
      "block_324.pkl\n",
      "block_325.pkl\n",
      "block_326.pkl\n",
      "block_327.pkl\n",
      "block_328.pkl\n",
      "block_329.pkl\n",
      "block_33.pkl\n",
      "block_330.pkl\n",
      "block_331.pkl\n",
      "block_332.pkl\n",
      "block_333.pkl\n",
      "block_334.pkl\n",
      "block_335.pkl\n",
      "block_336.pkl\n",
      "block_337.pkl\n",
      "block_338.pkl\n",
      "block_339.pkl\n",
      "block_34.pkl\n",
      "block_340.pkl\n",
      "block_341.pkl\n",
      "block_342.pkl\n",
      "block_343.pkl\n",
      "block_344.pkl\n",
      "block_345.pkl\n",
      "block_346.pkl\n",
      "block_347.pkl\n",
      "block_348.pkl\n",
      "block_349.pkl\n",
      "block_35.pkl\n",
      "block_350.pkl\n",
      "block_351.pkl\n",
      "block_352.pkl\n",
      "block_353.pkl\n",
      "block_354.pkl\n",
      "block_355.pkl\n",
      "block_356.pkl\n",
      "block_357.pkl\n",
      "block_358.pkl\n",
      "block_359.pkl\n",
      "block_36.pkl\n",
      "block_360.pkl\n",
      "block_361.pkl\n",
      "block_362.pkl\n",
      "block_363.pkl\n",
      "block_364.pkl\n",
      "block_365.pkl\n",
      "block_366.pkl\n",
      "block_367.pkl\n",
      "block_368.pkl\n",
      "block_369.pkl\n",
      "block_37.pkl\n",
      "block_370.pkl\n",
      "block_371.pkl\n",
      "block_372.pkl\n",
      "block_373.pkl\n",
      "block_374.pkl\n",
      "block_375.pkl\n",
      "block_376.pkl\n",
      "block_377.pkl\n",
      "block_378.pkl\n",
      "block_379.pkl\n",
      "block_38.pkl\n",
      "block_380.pkl\n",
      "block_381.pkl\n",
      "block_382.pkl\n",
      "block_383.pkl\n",
      "block_384.pkl\n",
      "block_385.pkl\n",
      "block_386.pkl\n",
      "block_387.pkl\n",
      "block_388.pkl\n",
      "block_389.pkl\n",
      "block_39.pkl\n",
      "block_390.pkl\n",
      "block_391.pkl\n",
      "block_392.pkl\n",
      "block_393.pkl\n",
      "block_394.pkl\n",
      "block_395.pkl\n",
      "block_396.pkl\n",
      "block_397.pkl\n",
      "block_398.pkl\n",
      "block_399.pkl\n",
      "block_4.pkl\n",
      "block_40.pkl\n",
      "block_400.pkl\n",
      "block_401.pkl\n",
      "block_402.pkl\n",
      "block_403.pkl\n",
      "block_404.pkl\n",
      "block_405.pkl\n",
      "block_406.pkl\n",
      "block_407.pkl\n",
      "block_408.pkl\n",
      "block_409.pkl\n",
      "block_41.pkl\n",
      "block_410.pkl\n",
      "block_411.pkl\n",
      "block_412.pkl\n",
      "block_413.pkl\n",
      "block_414.pkl\n",
      "block_415.pkl\n",
      "block_416.pkl\n",
      "block_417.pkl\n",
      "block_418.pkl\n",
      "block_419.pkl\n",
      "block_42.pkl\n",
      "block_420.pkl\n",
      "block_421.pkl\n",
      "block_422.pkl\n",
      "block_423.pkl\n",
      "block_424.pkl\n",
      "block_425.pkl\n",
      "block_426.pkl\n",
      "block_427.pkl\n",
      "block_428.pkl\n",
      "block_429.pkl\n",
      "block_43.pkl\n",
      "block_430.pkl\n",
      "block_431.pkl\n",
      "block_432.pkl\n",
      "block_433.pkl\n",
      "block_434.pkl\n",
      "block_435.pkl\n",
      "block_436.pkl\n",
      "block_437.pkl\n",
      "block_438.pkl\n",
      "block_439.pkl\n",
      "block_44.pkl\n",
      "block_440.pkl\n",
      "block_441.pkl\n",
      "block_442.pkl\n",
      "block_443.pkl\n",
      "block_444.pkl\n",
      "block_445.pkl\n",
      "block_446.pkl\n",
      "block_447.pkl\n",
      "block_448.pkl\n",
      "block_449.pkl\n",
      "block_45.pkl\n",
      "block_450.pkl\n",
      "block_451.pkl\n",
      "block_452.pkl\n",
      "block_453.pkl\n",
      "block_454.pkl\n",
      "block_455.pkl\n",
      "block_456.pkl\n",
      "block_457.pkl\n",
      "block_458.pkl\n",
      "block_459.pkl\n",
      "block_46.pkl\n",
      "block_460.pkl\n",
      "block_461.pkl\n",
      "block_462.pkl\n",
      "block_463.pkl\n",
      "block_464.pkl\n",
      "block_465.pkl\n",
      "block_466.pkl\n",
      "block_467.pkl\n",
      "block_468.pkl\n",
      "block_469.pkl\n",
      "block_47.pkl\n",
      "block_470.pkl\n",
      "block_471.pkl\n",
      "block_472.pkl\n",
      "block_473.pkl\n",
      "block_474.pkl\n",
      "block_475.pkl\n",
      "block_476.pkl\n",
      "block_477.pkl\n",
      "block_478.pkl\n",
      "block_479.pkl\n",
      "block_48.pkl\n",
      "block_480.pkl\n",
      "block_481.pkl\n",
      "block_482.pkl\n",
      "block_483.pkl\n",
      "block_484.pkl\n",
      "block_485.pkl\n",
      "block_486.pkl\n",
      "block_487.pkl\n",
      "block_488.pkl\n",
      "block_489.pkl\n",
      "block_49.pkl\n",
      "block_490.pkl\n",
      "block_491.pkl\n",
      "block_492.pkl\n",
      "block_493.pkl\n",
      "block_494.pkl\n",
      "block_495.pkl\n",
      "block_496.pkl\n",
      "block_497.pkl\n",
      "block_498.pkl\n",
      "block_499.pkl\n",
      "block_5.pkl\n",
      "block_50.pkl\n",
      "block_500.pkl\n",
      "block_501.pkl\n",
      "block_502.pkl\n",
      "block_51.pkl\n",
      "block_52.pkl\n",
      "block_53.pkl\n",
      "block_54.pkl\n",
      "block_55.pkl\n",
      "block_56.pkl\n",
      "block_57.pkl\n",
      "block_58.pkl\n",
      "block_59.pkl\n",
      "block_6.pkl\n",
      "block_60.pkl\n",
      "block_61.pkl\n",
      "block_62.pkl\n",
      "block_63.pkl\n",
      "block_64.pkl\n",
      "block_65.pkl\n",
      "block_66.pkl\n",
      "block_67.pkl\n",
      "block_68.pkl\n",
      "block_69.pkl\n",
      "block_7.pkl\n",
      "block_70.pkl\n",
      "block_71.pkl\n",
      "block_72.pkl\n",
      "block_73.pkl\n",
      "block_74.pkl\n",
      "block_75.pkl\n",
      "block_76.pkl\n",
      "block_77.pkl\n",
      "block_78.pkl\n",
      "block_79.pkl\n",
      "block_8.pkl\n",
      "block_80.pkl\n",
      "block_81.pkl\n",
      "block_82.pkl\n",
      "block_83.pkl\n",
      "block_84.pkl\n",
      "block_85.pkl\n",
      "block_86.pkl\n",
      "block_87.pkl\n",
      "block_88.pkl\n",
      "block_89.pkl\n",
      "block_9.pkl\n",
      "block_90.pkl\n",
      "block_91.pkl\n",
      "block_92.pkl\n",
      "block_93.pkl\n",
      "block_94.pkl\n",
      "block_95.pkl\n",
      "block_96.pkl\n",
      "block_97.pkl\n",
      "block_98.pkl\n",
      "block_99.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "class SPIMI:\n",
    "    # The structure is like:\n",
    "    # {TERM: [(docID, TF), ...], ...}\n",
    "    def __init__(self, index_dir=\"index_blocks\"):\n",
    "        self.index_dir = index_dir  # Directorio donde se guardarán los bloques temporales\n",
    "        self.block_counter = 0      # Contador para los bloques de índice\n",
    "        self.doc_count = 0          # Contador de documentos totales\n",
    "        self.idf = {}\n",
    "        self.length = {}\n",
    "        self.currentL = \"L\"\n",
    "\n",
    "        if not os.path.exists(self.index_dir):\n",
    "            os.makedirs(self.index_dir)\n",
    "\n",
    "    def spimi_invert(self, token_stream, disk_limit=400):\n",
    "        dictionary = {}\n",
    "        for _, row in token_stream.iterrows():\n",
    "            doc_id = row['Index']\n",
    "            token = row['ProcessedText']\n",
    "            \n",
    "            if token not in dictionary:\n",
    "                dictionary[token] = {}  # Crea un diccionario para el término\n",
    "            \n",
    "            if doc_id not in dictionary[token]:\n",
    "                dictionary[token][doc_id] = 1  # Primera aparición del término en el documento\n",
    "            else:\n",
    "                dictionary[token][doc_id] += 1  # Incrementa la frecuencia del término en el documento\n",
    "            dictionary_size = sys.getsizeof(dictionary)\n",
    "            if dictionary_size >= disk_limit:\n",
    "                self.write_block_to_disk(dictionary)\n",
    "                dictionary.clear()\n",
    "                \n",
    "        if dictionary:\n",
    "            self.write_block_to_disk(dictionary)\n",
    "    def merge(self):\n",
    "        for filename in os.listdir(self.index_dir):\n",
    "            print(filename)\n",
    "\n",
    "    def write_block_to_disk(self, dictionary):\n",
    "        sorted_terms = dict(sorted(dictionary.items())) \n",
    "        file_path = os.path.join(self.index_dir, f\"block_{self.block_counter}.pkl\")\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(sorted_terms, f)\n",
    "        \n",
    "        self.block_counter += 1\n",
    "\n",
    "s = SPIMI()  \n",
    "s.spimi_invert(pairs_df)\n",
    "s.merge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
